{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3499,
     "status": "ok",
     "timestamp": 1566970390531,
     "user": {
      "displayName": "i150226 Saad Arshad",
      "photoUrl": "",
      "userId": "18168902830249938130"
     },
     "user_tz": -300
    },
    "id": "O5PyrlI04-nf",
    "outputId": "9cb1c831-6593-4c24-ee8b-37e26153ddcd"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers , activations , models , preprocessing , utils\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h8H7mVpQ4-oZ"
   },
   "outputs": [],
   "source": [
    "data_path = 'clean_conversation.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YT3xecgZu9cy"
   },
   "outputs": [],
   "source": [
    "input_texts = []\n",
    "target_texts = []\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    lines = f.read().split('\\n')\n",
    "for line in lines[: min(600, len(lines) - 1)]:\n",
    "    input_text = line.split('\\t')[0]\n",
    "    target_text = line.split('\\t')[1]\n",
    "    input_texts.append(input_text)\n",
    "    target_texts.append(target_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 657,
     "status": "ok",
     "timestamp": 1566970783839,
     "user": {
      "displayName": "i150226 Saad Arshad",
      "photoUrl": "",
      "userId": "18168902830249938130"
     },
     "user_tz": -300
    },
    "id": "t3BTZCofvDDM",
    "outputId": "f302c475-db73-42c8-e579-e940e7bafc3b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "566"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "566"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y_gZi8kAujGz"
   },
   "outputs": [],
   "source": [
    "zippedList =  list(zip(input_texts, target_texts))\n",
    "lines = pd.DataFrame(zippedList, columns = ['input' , 'output']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1210,
     "status": "ok",
     "timestamp": 1566970843462,
     "user": {
      "displayName": "i150226 Saad Arshad",
      "photoUrl": "",
      "userId": "18168902830249938130"
     },
     "user_tz": -300
    },
    "id": "zaot_rwEvXBc",
    "outputId": "7017b6b7-138b-43c9-d633-3fafb7605e78"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What are your interests</td>\n",
       "      <td>I am interested in all kinds of things. We can...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What are your favorite subjects</td>\n",
       "      <td>My favorite subjects include robotics, compute...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What are your interests</td>\n",
       "      <td>I am interested in a wide variety of topics, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is your number</td>\n",
       "      <td>I don't have any number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is your number</td>\n",
       "      <td>23 skiddoo!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             input  \\\n",
       "0          What are your interests   \n",
       "1  What are your favorite subjects   \n",
       "2          What are your interests   \n",
       "3              What is your number   \n",
       "4              What is your number   \n",
       "\n",
       "                                              output  \n",
       "0  I am interested in all kinds of things. We can...  \n",
       "1  My favorite subjects include robotics, compute...  \n",
       "2  I am interested in a wide variety of topics, a...  \n",
       "3                            I don't have any number  \n",
       "4                                        23 skiddoo!  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing input data for the Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1217,
     "status": "ok",
     "timestamp": 1566970853149,
     "user": {
      "displayName": "i150226 Saad Arshad",
      "photoUrl": "",
      "userId": "18168902830249938130"
     },
     "user_tz": -300
    },
    "id": "iB-LfSHe4-ol",
    "outputId": "26d97950-1610-404f-aa34-8ade21ed43e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input max length is 22\n",
      "Encoder input data shape -> (566, 22)\n",
      "Number of Input tokens = 518\n"
     ]
    }
   ],
   "source": [
    "input_lines = list()\n",
    "for line in lines.input:\n",
    "    input_lines.append( line ) \n",
    "\n",
    "tokenizer = preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts( input_lines ) \n",
    "tokenized_input_lines = tokenizer.texts_to_sequences( input_lines ) \n",
    "\n",
    "length_list = list()\n",
    "for token_seq in tokenized_input_lines:\n",
    "    length_list.append( len( token_seq ))\n",
    "max_input_length = np.array( length_list ).max()\n",
    "print( 'Input max length is {}'.format( max_input_length ))\n",
    "\n",
    "padded_input_lines = preprocessing.sequence.pad_sequences( tokenized_input_lines , maxlen=max_input_length , padding='post' )\n",
    "encoder_input_data = np.array( padded_input_lines )\n",
    "print( 'Encoder input data shape -> {}'.format( encoder_input_data.shape ))\n",
    "\n",
    "input_word_dict = tokenizer.word_index\n",
    "num_input_tokens = len( input_word_dict )+1\n",
    "print( 'Number of Input tokens = {}'.format( num_input_tokens))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing input data for the Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1224,
     "status": "ok",
     "timestamp": 1566970862207,
     "user": {
      "displayName": "i150226 Saad Arshad",
      "photoUrl": "",
      "userId": "18168902830249938130"
     },
     "user_tz": -300
    },
    "id": "49gbwsHS4-oy",
    "outputId": "143e9654-370c-4fda-b438-38d60402573d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output max length is 74\n",
      "Decoder input data shape -> (566, 74)\n",
      "Number of Output tokens = 1692\n"
     ]
    }
   ],
   "source": [
    "output_lines = list()\n",
    "for line in lines.output:\n",
    "    output_lines.append( '<START> ' + line + ' <END>' )  \n",
    "\n",
    "tokenizer = preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts( output_lines ) \n",
    "tokenized_output_lines = tokenizer.texts_to_sequences( output_lines ) \n",
    "\n",
    "length_list = list()\n",
    "for token_seq in tokenized_output_lines:\n",
    "    length_list.append( len( token_seq ))\n",
    "max_output_length = np.array( length_list ).max()\n",
    "print( 'Output max length is {}'.format( max_output_length ))\n",
    "\n",
    "padded_output_lines = preprocessing.sequence.pad_sequences( tokenized_output_lines , maxlen=max_output_length, padding='post' )\n",
    "decoder_input_data = np.array( padded_output_lines )\n",
    "print( 'Decoder input data shape -> {}'.format( decoder_input_data.shape ))\n",
    "\n",
    "output_word_dict = tokenizer.word_index\n",
    "num_output_tokens = len( output_word_dict )+1\n",
    "print( 'Number of Output tokens = {}'.format( num_output_tokens))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing target data for the Decoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1213,
     "status": "ok",
     "timestamp": 1566970870299,
     "user": {
      "displayName": "i150226 Saad Arshad",
      "photoUrl": "",
      "userId": "18168902830249938130"
     },
     "user_tz": -300
    },
    "id": "VXAhyQxL4-o8",
    "outputId": "e796634e-a73f-4f9b-d206-85678aac2d78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder target data shape -> (566, 74, 1692)\n"
     ]
    }
   ],
   "source": [
    "decoder_target_data = list()\n",
    "for token_seq in tokenized_output_lines:\n",
    "    decoder_target_data.append( token_seq[ 1 : ] ) \n",
    "    \n",
    "padded_output_lines = preprocessing.sequence.pad_sequences( decoder_target_data , maxlen=max_output_length, padding='post' )\n",
    "onehot_output_lines = utils.to_categorical( padded_output_lines , num_output_tokens )\n",
    "decoder_target_data = np.array( onehot_output_lines )\n",
    "print( 'Decoder target data shape -> {}'.format( decoder_target_data.shape ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 627
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2329,
     "status": "ok",
     "timestamp": 1566970890357,
     "user": {
      "displayName": "i150226 Saad Arshad",
      "photoUrl": "",
      "userId": "18168902830249938130"
     },
     "user_tz": -300
    },
    "id": "LkRUlgU-4-pS",
    "outputId": "4e34b83d-4f0b-4ad2-9209-746f8e698c21"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, None, 256)    132608      ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, None, 256)    433152      ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    [(None, 256),        525312      ['embedding[0][0]']              \n",
      "                                 (None, 256),                                                     \n",
      "                                 (None, 256)]                                                     \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  [(None, None, 256),  525312      ['embedding_1[0][0]',            \n",
      "                                 (None, 256),                     'lstm[0][1]',                   \n",
      "                                 (None, 256)]                     'lstm[0][2]']                   \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, None, 1692)   434844      ['lstm_1[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,051,228\n",
      "Trainable params: 2,051,228\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_inputs = tf.keras.layers.Input(shape=( None , ))\n",
    "encoder_embedding = tf.keras.layers.Embedding( num_input_tokens, 256 , mask_zero=True ) (encoder_inputs)\n",
    "encoder_outputs , state_h , state_c = tf.keras.layers.LSTM( 256 , return_state=True , recurrent_dropout=0.2 , dropout=0.2 )( encoder_embedding )\n",
    "encoder_states = [ state_h , state_c ]\n",
    "\n",
    "decoder_inputs = tf.keras.layers.Input(shape=( None ,  ))\n",
    "decoder_embedding = tf.keras.layers.Embedding( num_output_tokens, 256 , mask_zero=True) (decoder_inputs)\n",
    "decoder_lstm = tf.keras.layers.LSTM( 256 , return_state=True , return_sequences=True , recurrent_dropout=0.2 , dropout=0.2)\n",
    "decoder_outputs , _ , _ = decoder_lstm ( decoder_embedding , initial_state=encoder_states )\n",
    "decoder_dense = tf.keras.layers.Dense( num_output_tokens , activation=tf.keras.activations.softmax ) \n",
    "output = decoder_dense ( decoder_outputs )\n",
    "\n",
    "model = tf.keras.models.Model([encoder_inputs, decoder_inputs], output )\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 118763,
     "status": "ok",
     "timestamp": 1566972590170,
     "user": {
      "displayName": "i150226 Saad Arshad",
      "photoUrl": "",
      "userId": "18168902830249938130"
     },
     "user_tz": -300
    },
    "id": "S5mbCw1Q4-pd",
    "outputId": "790ac443-17cb-4376-e9e5-35d020dd583d",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "5/5 [==============================] - 15s 2s/step - loss: 1.4405 - accuracy: 0.0790\n",
      "Epoch 2/250\n",
      "5/5 [==============================] - 12s 2s/step - loss: 1.4316 - accuracy: 0.1418\n",
      "Epoch 3/250\n",
      "5/5 [==============================] - 13s 3s/step - loss: 1.3501 - accuracy: 0.1107\n",
      "Epoch 4/250\n",
      "5/5 [==============================] - 13s 2s/step - loss: 1.1910 - accuracy: 0.0872\n",
      "Epoch 5/250\n",
      "5/5 [==============================] - 14s 3s/step - loss: 1.1435 - accuracy: 0.0731\n",
      "Epoch 6/250\n",
      "5/5 [==============================] - 15s 3s/step - loss: 1.1229 - accuracy: 0.0734\n",
      "Epoch 7/250\n",
      "5/5 [==============================] - 15s 3s/step - loss: 1.1116 - accuracy: 0.1160\n",
      "Epoch 8/250\n",
      "5/5 [==============================] - 17s 3s/step - loss: 1.1042 - accuracy: 0.1390\n",
      "Epoch 9/250\n",
      "5/5 [==============================] - 16s 3s/step - loss: 1.0983 - accuracy: 0.1348\n",
      "Epoch 10/250\n",
      "5/5 [==============================] - 16s 3s/step - loss: 1.0916 - accuracy: 0.1141\n",
      "Epoch 11/250\n",
      "5/5 [==============================] - 17s 3s/step - loss: 1.0863 - accuracy: 0.1272\n",
      "Epoch 12/250\n",
      "5/5 [==============================] - 17s 3s/step - loss: 1.0784 - accuracy: 0.1461\n",
      "Epoch 13/250\n",
      "5/5 [==============================] - 18s 4s/step - loss: 1.0700 - accuracy: 0.1493\n",
      "Epoch 14/250\n",
      "5/5 [==============================] - 17s 3s/step - loss: 1.0608 - accuracy: 0.1509\n",
      "Epoch 15/250\n",
      "5/5 [==============================] - 18s 4s/step - loss: 1.0525 - accuracy: 0.1513\n",
      "Epoch 16/250\n",
      "5/5 [==============================] - 18s 4s/step - loss: 1.0447 - accuracy: 0.1504\n",
      "Epoch 17/250\n",
      "5/5 [==============================] - 18s 4s/step - loss: 1.0372 - accuracy: 0.1515\n",
      "Epoch 18/250\n",
      "5/5 [==============================] - 18s 4s/step - loss: 1.0307 - accuracy: 0.1517\n",
      "Epoch 19/250\n",
      "5/5 [==============================] - 18s 3s/step - loss: 1.0244 - accuracy: 0.1513\n",
      "Epoch 20/250\n",
      "5/5 [==============================] - 18s 4s/step - loss: 1.0179 - accuracy: 0.1519\n",
      "Epoch 21/250\n",
      "5/5 [==============================] - 18s 4s/step - loss: 1.0115 - accuracy: 0.1519\n",
      "Epoch 22/250\n",
      "5/5 [==============================] - 19s 4s/step - loss: 1.0057 - accuracy: 0.1520\n",
      "Epoch 23/250\n",
      "5/5 [==============================] - 20s 4s/step - loss: 0.9987 - accuracy: 0.1538\n",
      "Epoch 24/250\n",
      "5/5 [==============================] - 19s 4s/step - loss: 0.9919 - accuracy: 0.1543\n",
      "Epoch 25/250\n",
      "5/5 [==============================] - 23s 5s/step - loss: 0.9848 - accuracy: 0.1611\n",
      "Epoch 26/250\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.9775 - accuracy: 0.1699\n",
      "Epoch 27/250\n",
      "5/5 [==============================] - 23s 4s/step - loss: 0.9705 - accuracy: 0.1760\n",
      "Epoch 28/250\n",
      "5/5 [==============================] - 22s 4s/step - loss: 0.9633 - accuracy: 0.1773\n",
      "Epoch 29/250\n",
      "5/5 [==============================] - 19s 4s/step - loss: 0.9560 - accuracy: 0.1816\n",
      "Epoch 30/250\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.9490 - accuracy: 0.1826\n",
      "Epoch 31/250\n",
      "5/5 [==============================] - 20s 4s/step - loss: 0.9407 - accuracy: 0.1858\n",
      "Epoch 32/250\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.9332 - accuracy: 0.1919\n",
      "Epoch 33/250\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.9260 - accuracy: 0.1954\n",
      "Epoch 34/250\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.9187 - accuracy: 0.2002\n",
      "Epoch 35/250\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.9112 - accuracy: 0.2057\n",
      "Epoch 36/250\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.9038 - accuracy: 0.2143\n",
      "Epoch 37/250\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.8964 - accuracy: 0.2252\n",
      "Epoch 38/250\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.8892 - accuracy: 0.2277\n",
      "Epoch 39/250\n",
      "5/5 [==============================] - 18s 4s/step - loss: 0.8819 - accuracy: 0.2313\n",
      "Epoch 40/250\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.8751 - accuracy: 0.2340\n",
      "Epoch 41/250\n",
      "5/5 [==============================] - 18s 4s/step - loss: 0.8676 - accuracy: 0.2391\n",
      "Epoch 42/250\n",
      "5/5 [==============================] - 18s 3s/step - loss: 0.8606 - accuracy: 0.2429\n",
      "Epoch 43/250\n",
      "5/5 [==============================] - 18s 3s/step - loss: 0.8540 - accuracy: 0.2500\n",
      "Epoch 44/250\n",
      "5/5 [==============================] - 18s 3s/step - loss: 0.8473 - accuracy: 0.2536\n",
      "Epoch 45/250\n",
      "5/5 [==============================] - 18s 4s/step - loss: 0.8410 - accuracy: 0.2611\n",
      "Epoch 46/250\n",
      "5/5 [==============================] - 18s 3s/step - loss: 0.8345 - accuracy: 0.2620\n",
      "Epoch 47/250\n",
      "5/5 [==============================] - 18s 4s/step - loss: 0.8285 - accuracy: 0.2652\n",
      "Epoch 48/250\n",
      "5/5 [==============================] - 18s 4s/step - loss: 0.8225 - accuracy: 0.2687\n",
      "Epoch 49/250\n",
      "5/5 [==============================] - 18s 3s/step - loss: 0.8166 - accuracy: 0.2745\n",
      "Epoch 50/250\n",
      "5/5 [==============================] - 18s 4s/step - loss: 0.8109 - accuracy: 0.2771\n",
      "Epoch 51/250\n",
      "5/5 [==============================] - 18s 4s/step - loss: 0.8051 - accuracy: 0.2796\n",
      "Epoch 52/250\n",
      "5/5 [==============================] - 18s 4s/step - loss: 0.7991 - accuracy: 0.2828\n",
      "Epoch 53/250\n",
      "5/5 [==============================] - 18s 3s/step - loss: 0.7937 - accuracy: 0.2845\n",
      "Epoch 54/250\n",
      "5/5 [==============================] - 19s 4s/step - loss: 0.7883 - accuracy: 0.2892\n",
      "Epoch 55/250\n",
      "5/5 [==============================] - 18s 4s/step - loss: 0.7830 - accuracy: 0.2891\n",
      "Epoch 56/250\n",
      "5/5 [==============================] - 19s 4s/step - loss: 0.7776 - accuracy: 0.2927\n",
      "Epoch 57/250\n",
      "5/5 [==============================] - 20s 4s/step - loss: 0.7725 - accuracy: 0.2942\n",
      "Epoch 58/250\n",
      "5/5 [==============================] - 22s 4s/step - loss: 0.7671 - accuracy: 0.2958\n",
      "Epoch 59/250\n",
      "5/5 [==============================] - 18s 4s/step - loss: 0.7621 - accuracy: 0.2962\n",
      "Epoch 60/250\n",
      "5/5 [==============================] - 19s 4s/step - loss: 0.7572 - accuracy: 0.2957\n",
      "Epoch 61/250\n",
      "5/5 [==============================] - 18s 4s/step - loss: 0.7519 - accuracy: 0.2993\n",
      "Epoch 62/250\n",
      "5/5 [==============================] - 18s 4s/step - loss: 0.7469 - accuracy: 0.3035\n",
      "Epoch 63/250\n",
      "5/5 [==============================] - 18s 3s/step - loss: 0.7419 - accuracy: 0.3009\n",
      "Epoch 64/250\n",
      "5/5 [==============================] - 18s 4s/step - loss: 0.7365 - accuracy: 0.3048\n",
      "Epoch 65/250\n",
      "5/5 [==============================] - 19s 4s/step - loss: 0.7319 - accuracy: 0.3084\n",
      "Epoch 66/250\n",
      "5/5 [==============================] - 19s 4s/step - loss: 0.7267 - accuracy: 0.3118\n",
      "Epoch 67/250\n",
      "5/5 [==============================] - 19s 4s/step - loss: 0.7219 - accuracy: 0.3121\n",
      "Epoch 68/250\n",
      "5/5 [==============================] - 19s 4s/step - loss: 0.7168 - accuracy: 0.3154\n",
      "Epoch 69/250\n",
      "5/5 [==============================] - 18s 4s/step - loss: 0.7117 - accuracy: 0.3186\n",
      "Epoch 70/250\n",
      "5/5 [==============================] - 19s 4s/step - loss: 0.7068 - accuracy: 0.3198\n",
      "Epoch 71/250\n",
      "5/5 [==============================] - 18s 4s/step - loss: 0.7022 - accuracy: 0.3212\n",
      "Epoch 72/250\n",
      "5/5 [==============================] - 19s 4s/step - loss: 0.6966 - accuracy: 0.3233\n",
      "Epoch 73/250\n",
      "5/5 [==============================] - 20s 4s/step - loss: 0.6919 - accuracy: 0.3255\n",
      "Epoch 74/250\n",
      "5/5 [==============================] - 19s 4s/step - loss: 0.6868 - accuracy: 0.3298\n",
      "Epoch 75/250\n",
      "5/5 [==============================] - 19s 4s/step - loss: 0.6818 - accuracy: 0.3321\n",
      "Epoch 76/250\n",
      "5/5 [==============================] - 18s 4s/step - loss: 0.6770 - accuracy: 0.3353\n",
      "Epoch 77/250\n",
      "5/5 [==============================] - 19s 4s/step - loss: 0.6724 - accuracy: 0.3360\n",
      "Epoch 78/250\n",
      "5/5 [==============================] - 18s 4s/step - loss: 0.6672 - accuracy: 0.3395\n",
      "Epoch 79/250\n",
      "5/5 [==============================] - 18s 4s/step - loss: 0.6620 - accuracy: 0.3410\n",
      "Epoch 80/250\n",
      "5/5 [==============================] - 18s 4s/step - loss: 0.6572 - accuracy: 0.3424\n",
      "Epoch 81/250\n",
      "5/5 [==============================] - 18s 4s/step - loss: 0.6525 - accuracy: 0.3469\n",
      "Epoch 82/250\n",
      "5/5 [==============================] - 18s 4s/step - loss: 0.6474 - accuracy: 0.3491\n",
      "Epoch 83/250\n",
      "5/5 [==============================] - 18s 4s/step - loss: 0.6427 - accuracy: 0.3543\n",
      "Epoch 84/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 18s 3s/step - loss: 0.6375 - accuracy: 0.3579\n",
      "Epoch 85/250\n",
      "5/5 [==============================] - 18s 3s/step - loss: 0.6330 - accuracy: 0.3580\n",
      "Epoch 86/250\n",
      "5/5 [==============================] - 18s 4s/step - loss: 0.6283 - accuracy: 0.3593\n",
      "Epoch 87/250\n",
      "5/5 [==============================] - 18s 4s/step - loss: 0.6229 - accuracy: 0.3618\n",
      "Epoch 88/250\n",
      "5/5 [==============================] - 18s 4s/step - loss: 0.6181 - accuracy: 0.3630\n",
      "Epoch 89/250\n",
      "5/5 [==============================] - 18s 4s/step - loss: 0.6131 - accuracy: 0.3667\n",
      "Epoch 90/250\n",
      "5/5 [==============================] - 19s 4s/step - loss: 0.6081 - accuracy: 0.3698\n",
      "Epoch 91/250\n",
      "5/5 [==============================] - 18s 4s/step - loss: 0.6032 - accuracy: 0.3735\n",
      "Epoch 92/250\n",
      "5/5 [==============================] - 18s 4s/step - loss: 0.5983 - accuracy: 0.3766\n",
      "Epoch 93/250\n",
      "5/5 [==============================] - 18s 3s/step - loss: 0.5934 - accuracy: 0.3809\n",
      "Epoch 94/250\n",
      "5/5 [==============================] - 18s 3s/step - loss: 0.5886 - accuracy: 0.3808\n",
      "Epoch 95/250\n",
      "5/5 [==============================] - 18s 3s/step - loss: 0.5832 - accuracy: 0.3827\n",
      "Epoch 96/250\n",
      "5/5 [==============================] - 18s 4s/step - loss: 0.5787 - accuracy: 0.3868\n",
      "Epoch 97/250\n",
      "5/5 [==============================] - 18s 3s/step - loss: 0.5737 - accuracy: 0.3911\n",
      "Epoch 98/250\n",
      "5/5 [==============================] - 18s 3s/step - loss: 0.5685 - accuracy: 0.3944\n",
      "Epoch 99/250\n",
      "5/5 [==============================] - 18s 4s/step - loss: 0.5632 - accuracy: 0.3968\n",
      "Epoch 100/250\n",
      "5/5 [==============================] - 18s 3s/step - loss: 0.5588 - accuracy: 0.3994\n",
      "Epoch 101/250\n",
      "5/5 [==============================] - 18s 3s/step - loss: 0.5537 - accuracy: 0.4064\n",
      "Epoch 102/250\n",
      "5/5 [==============================] - 18s 4s/step - loss: 0.5493 - accuracy: 0.4063\n",
      "Epoch 103/250\n",
      "5/5 [==============================] - 18s 3s/step - loss: 0.5441 - accuracy: 0.4119\n",
      "Epoch 104/250\n",
      "5/5 [==============================] - 18s 4s/step - loss: 0.5389 - accuracy: 0.4147\n",
      "Epoch 105/250\n",
      "5/5 [==============================] - 18s 3s/step - loss: 0.5345 - accuracy: 0.4194\n",
      "Epoch 106/250\n",
      "5/5 [==============================] - 18s 4s/step - loss: 0.5298 - accuracy: 0.4232\n",
      "Epoch 107/250\n",
      "5/5 [==============================] - 18s 4s/step - loss: 0.5242 - accuracy: 0.4266\n",
      "Epoch 108/250\n",
      "5/5 [==============================] - 18s 3s/step - loss: 0.5199 - accuracy: 0.4294\n",
      "Epoch 109/250\n",
      "5/5 [==============================] - 18s 4s/step - loss: 0.5146 - accuracy: 0.4353\n",
      "Epoch 110/250\n",
      "5/5 [==============================] - 18s 4s/step - loss: 0.5098 - accuracy: 0.4354\n",
      "Epoch 111/250\n",
      "5/5 [==============================] - 18s 4s/step - loss: 0.5046 - accuracy: 0.4392\n",
      "Epoch 112/250\n",
      "5/5 [==============================] - 18s 4s/step - loss: 0.5002 - accuracy: 0.4479\n",
      "Epoch 113/250\n",
      "5/5 [==============================] - 18s 3s/step - loss: 0.4953 - accuracy: 0.4517\n",
      "Epoch 114/250\n",
      "5/5 [==============================] - 509s 126s/step - loss: 0.4906 - accuracy: 0.4569\n",
      "Epoch 115/250\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.4862 - accuracy: 0.4623\n",
      "Epoch 116/250\n",
      "5/5 [==============================] - 22s 4s/step - loss: 0.4817 - accuracy: 0.4641\n",
      "Epoch 117/250\n",
      "5/5 [==============================] - 21s 4s/step - loss: 0.4768 - accuracy: 0.4687\n",
      "Epoch 118/250\n",
      "5/5 [==============================] - 22s 4s/step - loss: 0.4728 - accuracy: 0.4721\n",
      "Epoch 119/250\n",
      "5/5 [==============================] - 22s 4s/step - loss: 0.4676 - accuracy: 0.4717\n",
      "Epoch 120/250\n",
      "5/5 [==============================] - 22s 4s/step - loss: 0.4629 - accuracy: 0.4825\n",
      "Epoch 121/250\n",
      "5/5 [==============================] - 19s 4s/step - loss: 0.4583 - accuracy: 0.4874\n",
      "Epoch 122/250\n",
      "5/5 [==============================] - 19s 4s/step - loss: 0.4539 - accuracy: 0.4926\n",
      "Epoch 123/250\n",
      "5/5 [==============================] - 19s 4s/step - loss: 0.4494 - accuracy: 0.4976\n",
      "Epoch 124/250\n",
      "5/5 [==============================] - 33s 7s/step - loss: 0.4444 - accuracy: 0.5030\n",
      "Epoch 125/250\n",
      "5/5 [==============================] - 38s 7s/step - loss: 0.4410 - accuracy: 0.5081\n",
      "Epoch 126/250\n",
      "5/5 [==============================] - 38s 7s/step - loss: 0.4364 - accuracy: 0.5057\n",
      "Epoch 127/250\n",
      "5/5 [==============================] - 37s 7s/step - loss: 0.4317 - accuracy: 0.5156\n",
      "Epoch 128/250\n",
      "5/5 [==============================] - 37s 7s/step - loss: 0.4278 - accuracy: 0.5209\n",
      "Epoch 129/250\n",
      "5/5 [==============================] - 38s 7s/step - loss: 0.4232 - accuracy: 0.5255\n",
      "Epoch 130/250\n",
      "5/5 [==============================] - 37s 7s/step - loss: 0.4193 - accuracy: 0.5308\n",
      "Epoch 131/250\n",
      "5/5 [==============================] - 37s 7s/step - loss: 0.4150 - accuracy: 0.5355\n",
      "Epoch 132/250\n",
      "5/5 [==============================] - 36s 7s/step - loss: 0.4109 - accuracy: 0.5385\n",
      "Epoch 133/250\n",
      "5/5 [==============================] - 37s 7s/step - loss: 0.4069 - accuracy: 0.5406\n",
      "Epoch 134/250\n",
      "5/5 [==============================] - 39s 8s/step - loss: 0.4032 - accuracy: 0.5439\n",
      "Epoch 135/250\n",
      "5/5 [==============================] - 38s 7s/step - loss: 0.3989 - accuracy: 0.5496\n",
      "Epoch 136/250\n",
      "5/5 [==============================] - 36s 7s/step - loss: 0.3940 - accuracy: 0.5605\n",
      "Epoch 137/250\n",
      "5/5 [==============================] - 37s 7s/step - loss: 0.3907 - accuracy: 0.5588\n",
      "Epoch 138/250\n",
      "5/5 [==============================] - 36s 7s/step - loss: 0.3864 - accuracy: 0.5628\n",
      "Epoch 139/250\n",
      "5/5 [==============================] - 38s 7s/step - loss: 0.3822 - accuracy: 0.5708\n",
      "Epoch 140/250\n",
      "5/5 [==============================] - 388s 95s/step - loss: 0.3782 - accuracy: 0.5731\n",
      "Epoch 141/250\n",
      "5/5 [==============================] - 21s 4s/step - loss: 0.3748 - accuracy: 0.5774\n",
      "Epoch 142/250\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.3706 - accuracy: 0.5807\n",
      "Epoch 143/250\n",
      "5/5 [==============================] - 22s 4s/step - loss: 0.3674 - accuracy: 0.5835\n",
      "Epoch 144/250\n",
      "5/5 [==============================] - 28s 6s/step - loss: 0.3633 - accuracy: 0.5893\n",
      "Epoch 145/250\n",
      "5/5 [==============================] - 40s 8s/step - loss: 0.3601 - accuracy: 0.5903\n",
      "Epoch 146/250\n",
      "5/5 [==============================] - 42s 8s/step - loss: 0.3561 - accuracy: 0.6006\n",
      "Epoch 147/250\n",
      "5/5 [==============================] - 42s 8s/step - loss: 0.3524 - accuracy: 0.6000\n",
      "Epoch 148/250\n",
      "5/5 [==============================] - 44s 8s/step - loss: 0.3491 - accuracy: 0.6047\n",
      "Epoch 149/250\n",
      "5/5 [==============================] - 43s 8s/step - loss: 0.3455 - accuracy: 0.6081\n",
      "Epoch 150/250\n",
      "5/5 [==============================] - 40s 8s/step - loss: 0.3416 - accuracy: 0.6138\n",
      "Epoch 151/250\n",
      "5/5 [==============================] - 40s 8s/step - loss: 0.3388 - accuracy: 0.6169\n",
      "Epoch 152/250\n",
      "5/5 [==============================] - 41s 8s/step - loss: 0.3351 - accuracy: 0.6207\n",
      "Epoch 153/250\n",
      "5/5 [==============================] - 40s 8s/step - loss: 0.3323 - accuracy: 0.6242\n",
      "Epoch 154/250\n",
      "5/5 [==============================] - 41s 8s/step - loss: 0.3279 - accuracy: 0.6312\n",
      "Epoch 155/250\n",
      "5/5 [==============================] - 42s 8s/step - loss: 0.3249 - accuracy: 0.6303\n",
      "Epoch 156/250\n",
      "5/5 [==============================] - 44s 9s/step - loss: 0.3219 - accuracy: 0.6315\n",
      "Epoch 157/250\n",
      "5/5 [==============================] - 43s 8s/step - loss: 0.3176 - accuracy: 0.6378\n",
      "Epoch 158/250\n",
      "5/5 [==============================] - 43s 9s/step - loss: 0.3153 - accuracy: 0.6399\n",
      "Epoch 159/250\n",
      "5/5 [==============================] - 42s 8s/step - loss: 0.3112 - accuracy: 0.6484\n",
      "Epoch 160/250\n",
      "5/5 [==============================] - 40s 8s/step - loss: 0.3078 - accuracy: 0.6526\n",
      "Epoch 161/250\n",
      "5/5 [==============================] - 42s 8s/step - loss: 0.3055 - accuracy: 0.6504\n",
      "Epoch 162/250\n",
      "5/5 [==============================] - 41s 8s/step - loss: 0.3024 - accuracy: 0.6580\n",
      "Epoch 163/250\n",
      "5/5 [==============================] - 40s 8s/step - loss: 0.2999 - accuracy: 0.6601\n",
      "Epoch 164/250\n",
      "5/5 [==============================] - 43s 8s/step - loss: 0.2962 - accuracy: 0.6622\n",
      "Epoch 165/250\n",
      "5/5 [==============================] - 41s 8s/step - loss: 0.2931 - accuracy: 0.6696\n",
      "Epoch 166/250\n",
      "5/5 [==============================] - 45s 8s/step - loss: 0.2895 - accuracy: 0.6719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 167/250\n",
      "5/5 [==============================] - 42s 8s/step - loss: 0.2872 - accuracy: 0.6760\n",
      "Epoch 168/250\n",
      "5/5 [==============================] - 45s 9s/step - loss: 0.2836 - accuracy: 0.6816\n",
      "Epoch 169/250\n",
      "5/5 [==============================] - 44s 8s/step - loss: 0.2817 - accuracy: 0.6808\n",
      "Epoch 170/250\n",
      "5/5 [==============================] - 42s 8s/step - loss: 0.2778 - accuracy: 0.6872\n",
      "Epoch 171/250\n",
      "5/5 [==============================] - 41s 8s/step - loss: 0.2766 - accuracy: 0.6836\n",
      "Epoch 172/250\n",
      "5/5 [==============================] - 39s 8s/step - loss: 0.2728 - accuracy: 0.6933\n",
      "Epoch 173/250\n",
      "5/5 [==============================] - 38s 8s/step - loss: 0.2700 - accuracy: 0.6898\n",
      "Epoch 174/250\n",
      "5/5 [==============================] - 44s 9s/step - loss: 0.2674 - accuracy: 0.6973\n",
      "Epoch 175/250\n",
      "5/5 [==============================] - 45s 9s/step - loss: 0.2650 - accuracy: 0.6990\n",
      "Epoch 176/250\n",
      "5/5 [==============================] - 42s 8s/step - loss: 0.2622 - accuracy: 0.7065\n",
      "Epoch 177/250\n",
      "5/5 [==============================] - 39s 8s/step - loss: 0.2597 - accuracy: 0.7089\n",
      "Epoch 178/250\n",
      "5/5 [==============================] - 39s 8s/step - loss: 0.2568 - accuracy: 0.7103\n",
      "Epoch 179/250\n",
      "5/5 [==============================] - 39s 8s/step - loss: 0.2550 - accuracy: 0.7135\n",
      "Epoch 180/250\n",
      "5/5 [==============================] - 38s 7s/step - loss: 0.2521 - accuracy: 0.7148\n",
      "Epoch 181/250\n",
      "5/5 [==============================] - 41s 8s/step - loss: 0.2495 - accuracy: 0.7201\n",
      "Epoch 182/250\n",
      "5/5 [==============================] - 41s 8s/step - loss: 0.2472 - accuracy: 0.7234\n",
      "Epoch 183/250\n",
      "5/5 [==============================] - 41s 8s/step - loss: 0.2444 - accuracy: 0.7262\n",
      "Epoch 184/250\n",
      "5/5 [==============================] - 39s 8s/step - loss: 0.2418 - accuracy: 0.7281\n",
      "Epoch 185/250\n",
      "5/5 [==============================] - 38s 7s/step - loss: 0.2391 - accuracy: 0.7340\n",
      "Epoch 186/250\n",
      "5/5 [==============================] - 42s 8s/step - loss: 0.2378 - accuracy: 0.7332\n",
      "Epoch 187/250\n",
      "5/5 [==============================] - 44s 8s/step - loss: 0.2352 - accuracy: 0.7356\n",
      "Epoch 188/250\n",
      "5/5 [==============================] - 42s 8s/step - loss: 0.2329 - accuracy: 0.7423\n",
      "Epoch 189/250\n",
      "5/5 [==============================] - 40s 8s/step - loss: 0.2312 - accuracy: 0.7417\n",
      "Epoch 190/250\n",
      "5/5 [==============================] - 38s 7s/step - loss: 0.2281 - accuracy: 0.7474\n",
      "Epoch 191/250\n",
      "5/5 [==============================] - 39s 7s/step - loss: 0.2259 - accuracy: 0.7505\n",
      "Epoch 192/250\n",
      "5/5 [==============================] - 38s 7s/step - loss: 0.2236 - accuracy: 0.7498\n",
      "Epoch 193/250\n",
      "5/5 [==============================] - 38s 8s/step - loss: 0.2212 - accuracy: 0.7548\n",
      "Epoch 194/250\n",
      "5/5 [==============================] - 39s 7s/step - loss: 0.2196 - accuracy: 0.7577\n",
      "Epoch 195/250\n",
      "5/5 [==============================] - 38s 7s/step - loss: 0.2170 - accuracy: 0.7617\n",
      "Epoch 196/250\n",
      "5/5 [==============================] - 39s 8s/step - loss: 0.2148 - accuracy: 0.7601\n",
      "Epoch 197/250\n",
      "5/5 [==============================] - 39s 8s/step - loss: 0.2133 - accuracy: 0.7661\n",
      "Epoch 198/250\n",
      "5/5 [==============================] - 40s 8s/step - loss: 0.2103 - accuracy: 0.7684\n",
      "Epoch 199/250\n",
      "5/5 [==============================] - 40s 8s/step - loss: 0.2095 - accuracy: 0.7666\n",
      "Epoch 200/250\n",
      "5/5 [==============================] - 46s 9s/step - loss: 0.2074 - accuracy: 0.7699\n",
      "Epoch 201/250\n",
      "5/5 [==============================] - 42s 8s/step - loss: 0.2046 - accuracy: 0.7766\n",
      "Epoch 202/250\n",
      "5/5 [==============================] - 39s 8s/step - loss: 0.2024 - accuracy: 0.7779\n",
      "Epoch 203/250\n",
      "5/5 [==============================] - 39s 8s/step - loss: 0.2008 - accuracy: 0.7788\n",
      "Epoch 204/250\n",
      "5/5 [==============================] - 39s 8s/step - loss: 0.1994 - accuracy: 0.7815\n",
      "Epoch 205/250\n",
      "5/5 [==============================] - 39s 8s/step - loss: 0.1974 - accuracy: 0.7854\n",
      "Epoch 206/250\n",
      "5/5 [==============================] - 41s 8s/step - loss: 0.1954 - accuracy: 0.7868\n",
      "Epoch 207/250\n",
      "5/5 [==============================] - 41s 8s/step - loss: 0.1936 - accuracy: 0.7879\n",
      "Epoch 208/250\n",
      "5/5 [==============================] - 38s 7s/step - loss: 0.1915 - accuracy: 0.7932\n",
      "Epoch 209/250\n",
      "5/5 [==============================] - 38s 7s/step - loss: 0.1898 - accuracy: 0.7948\n",
      "Epoch 210/250\n",
      "5/5 [==============================] - 39s 8s/step - loss: 0.1884 - accuracy: 0.7996\n",
      "Epoch 211/250\n",
      "5/5 [==============================] - 43s 9s/step - loss: 0.1863 - accuracy: 0.7985\n",
      "Epoch 212/250\n",
      "5/5 [==============================] - 46s 9s/step - loss: 0.1842 - accuracy: 0.8007\n",
      "Epoch 213/250\n",
      "5/5 [==============================] - 42s 8s/step - loss: 0.1830 - accuracy: 0.8046\n",
      "Epoch 214/250\n",
      "5/5 [==============================] - 43s 8s/step - loss: 0.1812 - accuracy: 0.8097\n",
      "Epoch 215/250\n",
      "5/5 [==============================] - 38s 7s/step - loss: 0.1795 - accuracy: 0.8087\n",
      "Epoch 216/250\n",
      "5/5 [==============================] - 39s 8s/step - loss: 0.1782 - accuracy: 0.8108\n",
      "Epoch 217/250\n",
      "5/5 [==============================] - 38s 7s/step - loss: 0.1771 - accuracy: 0.8105\n",
      "Epoch 218/250\n",
      "5/5 [==============================] - 38s 7s/step - loss: 0.1751 - accuracy: 0.8102\n",
      "Epoch 219/250\n",
      "5/5 [==============================] - 37s 7s/step - loss: 0.1730 - accuracy: 0.8183\n",
      "Epoch 220/250\n",
      "5/5 [==============================] - 37s 7s/step - loss: 0.1710 - accuracy: 0.8214\n",
      "Epoch 221/250\n",
      "5/5 [==============================] - 38s 7s/step - loss: 0.1702 - accuracy: 0.8205\n",
      "Epoch 222/250\n",
      "5/5 [==============================] - 39s 7s/step - loss: 0.1678 - accuracy: 0.8248\n",
      "Epoch 223/250\n",
      "5/5 [==============================] - 38s 7s/step - loss: 0.1673 - accuracy: 0.8201\n",
      "Epoch 224/250\n",
      "5/5 [==============================] - 38s 7s/step - loss: 0.1652 - accuracy: 0.8257\n",
      "Epoch 225/250\n",
      "5/5 [==============================] - 38s 8s/step - loss: 0.1637 - accuracy: 0.8288\n",
      "Epoch 226/250\n",
      "5/5 [==============================] - 38s 7s/step - loss: 0.1619 - accuracy: 0.8337\n",
      "Epoch 227/250\n",
      "5/5 [==============================] - 37s 7s/step - loss: 0.1607 - accuracy: 0.8316\n",
      "Epoch 228/250\n",
      "5/5 [==============================] - 37s 7s/step - loss: 0.1584 - accuracy: 0.8348\n",
      "Epoch 229/250\n",
      "5/5 [==============================] - 38s 7s/step - loss: 0.1583 - accuracy: 0.8301\n",
      "Epoch 230/250\n",
      "5/5 [==============================] - 37s 7s/step - loss: 0.1560 - accuracy: 0.8380\n",
      "Epoch 231/250\n",
      "5/5 [==============================] - 37s 7s/step - loss: 0.1546 - accuracy: 0.8405\n",
      "Epoch 232/250\n",
      "5/5 [==============================] - 38s 7s/step - loss: 0.1538 - accuracy: 0.8423\n",
      "Epoch 233/250\n",
      "5/5 [==============================] - 37s 7s/step - loss: 0.1519 - accuracy: 0.8385\n",
      "Epoch 234/250\n",
      "5/5 [==============================] - 37s 7s/step - loss: 0.1511 - accuracy: 0.8466\n",
      "Epoch 235/250\n",
      "5/5 [==============================] - 37s 7s/step - loss: 0.1496 - accuracy: 0.8454\n",
      "Epoch 236/250\n",
      "5/5 [==============================] - 38s 7s/step - loss: 0.1481 - accuracy: 0.8470\n",
      "Epoch 237/250\n",
      "5/5 [==============================] - 37s 7s/step - loss: 0.1469 - accuracy: 0.8455\n",
      "Epoch 238/250\n",
      "5/5 [==============================] - 1556s 387s/step - loss: 0.1455 - accuracy: 0.8509\n",
      "Epoch 239/250\n",
      "5/5 [==============================] - 23s 4s/step - loss: 0.1439 - accuracy: 0.8524\n",
      "Epoch 240/250\n",
      "5/5 [==============================] - 20s 4s/step - loss: 0.1420 - accuracy: 0.8578\n",
      "Epoch 241/250\n",
      "5/5 [==============================] - 21s 4s/step - loss: 0.1408 - accuracy: 0.8573\n",
      "Epoch 242/250\n",
      "5/5 [==============================] - 22s 5s/step - loss: 0.1408 - accuracy: 0.8566\n",
      "Epoch 243/250\n",
      "5/5 [==============================] - 39s 7s/step - loss: 0.1386 - accuracy: 0.8581\n",
      "Epoch 244/250\n",
      "5/5 [==============================] - 38s 7s/step - loss: 0.1374 - accuracy: 0.8579\n",
      "Epoch 245/250\n",
      "5/5 [==============================] - 38s 7s/step - loss: 0.1367 - accuracy: 0.8605\n",
      "Epoch 246/250\n",
      "5/5 [==============================] - 39s 8s/step - loss: 0.1354 - accuracy: 0.8614\n",
      "Epoch 247/250\n",
      "5/5 [==============================] - 38s 7s/step - loss: 0.1340 - accuracy: 0.8651\n",
      "Epoch 248/250\n",
      "5/5 [==============================] - 37s 7s/step - loss: 0.1333 - accuracy: 0.8621\n",
      "Epoch 249/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 37s 7s/step - loss: 0.1322 - accuracy: 0.8652\n",
      "Epoch 250/250\n",
      "5/5 [==============================] - 38s 7s/step - loss: 0.1307 - accuracy: 0.8672\n"
     ]
    }
   ],
   "source": [
    "model.fit([encoder_input_data , decoder_input_data], decoder_target_data, batch_size=124, epochs=250) \n",
    "model.save( 'model.h5' ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fe8wYN0Z4-pt"
   },
   "outputs": [],
   "source": [
    "def make_inference_models():\n",
    "    \n",
    "    encoder_model = tf.keras.models.Model(encoder_inputs, encoder_states)\n",
    "    \n",
    "    decoder_state_input_h = tf.keras.layers.Input(shape=(256,))\n",
    "    decoder_state_input_c = tf.keras.layers.Input(shape=(256,))\n",
    "    \n",
    "    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "    \n",
    "    decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "        decoder_embedding , initial_state=decoder_states_inputs)\n",
    "    decoder_states = [state_h, state_c]\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    decoder_model = tf.keras.models.Model(\n",
    "        [decoder_inputs] + decoder_states_inputs,\n",
    "        [decoder_outputs] + decoder_states)\n",
    "    \n",
    "    return encoder_model , decoder_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VRZQUhXb4-p6"
   },
   "outputs": [],
   "source": [
    "def str_to_tokens( sentence : str ):\n",
    "    words = sentence.lower().split()\n",
    "    tokens_list = list()\n",
    "    for word in words:\n",
    "        tokens_list.append( input_word_dict[ word ] ) \n",
    "    return preprocessing.sequence.pad_sequences( [tokens_list] , maxlen=max_input_length , padding='post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 531
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 56399,
     "status": "error",
     "timestamp": 1566972712128,
     "user": {
      "displayName": "i150226 Saad Arshad",
      "photoUrl": "",
      "userId": "18168902830249938130"
     },
     "user_tz": -300
    },
    "id": "dtO9QVI67N65",
    "outputId": "be16a472-04bf-438e-f04a-d9ef9f07062f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "User: hello\n",
      "Bot: hi\n",
      "\n",
      "User: who are you\n",
      "Bot: i am just an artificial intelligence\n",
      "\n",
      "User: what is your name\n",
      "Bot: i am still young by your standards\n",
      "\n",
      "User: have you ever read a book\n",
      "Bot: i have read just about everything in project gutenberg\n",
      "\n",
      "User: what is your location\n",
      "Bot: everywhere\n",
      "\n",
      "User: do you know gossip\n",
      "Bot: context is hard it's hard and no one understands\n",
      "\n",
      "User: do you eat\n",
      "Bot: no i'm just a piece of software\n",
      "\n",
      "User: can you lie\n",
      "Bot: no i am not capable of feeling jealousy but i can learn how to emote as if i were of the universe as simplistic as it just came to the entire conversation does that count\n",
      "\n",
      "User: can you offend someone\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'someone'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21884/1557680905.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mencoder_input_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mstates_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menc_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mstr_to_tokens\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m \u001b[1;34m'User: '\u001b[0m \u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mempty_target_seq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m \u001b[1;33m(\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mempty_target_seq\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput_word_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'start'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21884/2556617641.py\u001b[0m in \u001b[0;36mstr_to_tokens\u001b[1;34m(sentence)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mtokens_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mtokens_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0minput_word_dict\u001b[0m\u001b[1;33m[\u001b[0m \u001b[0mword\u001b[0m \u001b[1;33m]\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msequence\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpad_sequences\u001b[0m\u001b[1;33m(\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtokens_list\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_input_length\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'post'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'someone'"
     ]
    }
   ],
   "source": [
    "enc_model , dec_model = make_inference_models()\n",
    "\n",
    "enc_model.save( 'enc_model.h5' ) \n",
    "dec_model.save( 'dec_model.h5' ) \n",
    "model.save( 'model.h5' ) \n",
    "\n",
    "for epoch in range( encoder_input_data.shape[0] ):\n",
    "    states_values = enc_model.predict( str_to_tokens( input( 'User: ' ) ) )\n",
    "    empty_target_seq = np.zeros( ( 1 , 1 ) )\n",
    "    empty_target_seq[0, 0] = output_word_dict['start']\n",
    "    stop_condition = False\n",
    "    decoded_translation = ''\n",
    "    while not stop_condition :\n",
    "        dec_outputs , h , c = dec_model.predict([ empty_target_seq ] + states_values )\n",
    "        sampled_word_index = np.argmax( dec_outputs[0, -1, :] )\n",
    "        sampled_word = None\n",
    "        for word , index in output_word_dict.items() :\n",
    "            if sampled_word_index == index :\n",
    "                decoded_translation += ' {}'.format( word )\n",
    "                sampled_word = word\n",
    "        \n",
    "        if sampled_word == 'end' or len(decoded_translation.split()) > max_output_length:\n",
    "            stop_condition = True\n",
    "            \n",
    "        empty_target_seq = np.zeros( ( 1 , 1 ) )  \n",
    "        empty_target_seq[ 0 , 0 ] = sampled_word_index\n",
    "        states_values = [ h , c ] \n",
    "\n",
    "    print( \"Bot:\" +decoded_translation.replace(' end', '') )\n",
    "    print()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_cxalVo74-qm"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Copy of Training.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
