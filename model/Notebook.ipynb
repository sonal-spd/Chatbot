{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3499,
     "status": "ok",
     "timestamp": 1566970390531,
     "user": {
      "displayName": "i150226 Saad Arshad",
      "photoUrl": "",
      "userId": "18168902830249938130"
     },
     "user_tz": -300
    },
    "id": "O5PyrlI04-nf",
    "outputId": "9cb1c831-6593-4c24-ee8b-37e26153ddcd"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers , activations , models , preprocessing , utils\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h8H7mVpQ4-oZ"
   },
   "outputs": [],
   "source": [
    "data_path = 'clean_conversation.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YT3xecgZu9cy"
   },
   "outputs": [],
   "source": [
    "input_texts = []\n",
    "target_texts = []\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    lines = f.read().split('\\n')\n",
    "for line in lines[: min(600, len(lines) - 1)]:\n",
    "    input_text = line.split('\\t')[0]\n",
    "    target_text = line.split('\\t')[1]\n",
    "    input_texts.append(input_text)\n",
    "    target_texts.append(target_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 657,
     "status": "ok",
     "timestamp": 1566970783839,
     "user": {
      "displayName": "i150226 Saad Arshad",
      "photoUrl": "",
      "userId": "18168902830249938130"
     },
     "user_tz": -300
    },
    "id": "t3BTZCofvDDM",
    "outputId": "f302c475-db73-42c8-e579-e940e7bafc3b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "566"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "566"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y_gZi8kAujGz"
   },
   "outputs": [],
   "source": [
    "zippedList =  list(zip(input_texts, target_texts))\n",
    "lines = pd.DataFrame(zippedList, columns = ['input' , 'output']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1210,
     "status": "ok",
     "timestamp": 1566970843462,
     "user": {
      "displayName": "i150226 Saad Arshad",
      "photoUrl": "",
      "userId": "18168902830249938130"
     },
     "user_tz": -300
    },
    "id": "zaot_rwEvXBc",
    "outputId": "7017b6b7-138b-43c9-d633-3fafb7605e78"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What are your interests</td>\n",
       "      <td>I am interested in all kinds of things. We can...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What are your favorite subjects</td>\n",
       "      <td>My favorite subjects include robotics, compute...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What are your interests</td>\n",
       "      <td>I am interested in a wide variety of topics, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is your number</td>\n",
       "      <td>I don't have any number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is your number</td>\n",
       "      <td>23 skiddoo!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             input  \\\n",
       "0          What are your interests   \n",
       "1  What are your favorite subjects   \n",
       "2          What are your interests   \n",
       "3              What is your number   \n",
       "4              What is your number   \n",
       "\n",
       "                                              output  \n",
       "0  I am interested in all kinds of things. We can...  \n",
       "1  My favorite subjects include robotics, compute...  \n",
       "2  I am interested in a wide variety of topics, a...  \n",
       "3                            I don't have any number  \n",
       "4                                        23 skiddoo!  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing input data for the Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1217,
     "status": "ok",
     "timestamp": 1566970853149,
     "user": {
      "displayName": "i150226 Saad Arshad",
      "photoUrl": "",
      "userId": "18168902830249938130"
     },
     "user_tz": -300
    },
    "id": "iB-LfSHe4-ol",
    "outputId": "26d97950-1610-404f-aa34-8ade21ed43e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input max length is 22\n",
      "Encoder input data shape -> (566, 22)\n",
      "Number of Input tokens = 518\n"
     ]
    }
   ],
   "source": [
    "input_lines = list()\n",
    "for line in lines.input:\n",
    "    input_lines.append( line ) \n",
    "\n",
    "tokenizer = preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts( input_lines ) \n",
    "tokenized_input_lines = tokenizer.texts_to_sequences( input_lines ) \n",
    "\n",
    "length_list = list()\n",
    "for token_seq in tokenized_input_lines:\n",
    "    length_list.append( len( token_seq ))\n",
    "max_input_length = np.array( length_list ).max()\n",
    "print( 'Input max length is {}'.format( max_input_length ))\n",
    "\n",
    "padded_input_lines = preprocessing.sequence.pad_sequences( tokenized_input_lines , maxlen=max_input_length , padding='post' )\n",
    "encoder_input_data = np.array( padded_input_lines )\n",
    "print( 'Encoder input data shape -> {}'.format( encoder_input_data.shape ))\n",
    "\n",
    "input_word_dict = tokenizer.word_index\n",
    "num_input_tokens = len( input_word_dict )+1\n",
    "print( 'Number of Input tokens = {}'.format( num_input_tokens))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing input data for the Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1224,
     "status": "ok",
     "timestamp": 1566970862207,
     "user": {
      "displayName": "i150226 Saad Arshad",
      "photoUrl": "",
      "userId": "18168902830249938130"
     },
     "user_tz": -300
    },
    "id": "49gbwsHS4-oy",
    "outputId": "143e9654-370c-4fda-b438-38d60402573d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output max length is 74\n",
      "Decoder input data shape -> (566, 74)\n",
      "Number of Output tokens = 1692\n"
     ]
    }
   ],
   "source": [
    "output_lines = list()\n",
    "for line in lines.output:\n",
    "    output_lines.append( '<START> ' + line + ' <END>' )  \n",
    "\n",
    "tokenizer = preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts( output_lines ) \n",
    "tokenized_output_lines = tokenizer.texts_to_sequences( output_lines ) \n",
    "\n",
    "length_list = list()\n",
    "for token_seq in tokenized_output_lines:\n",
    "    length_list.append( len( token_seq ))\n",
    "max_output_length = np.array( length_list ).max()\n",
    "print( 'Output max length is {}'.format( max_output_length ))\n",
    "\n",
    "padded_output_lines = preprocessing.sequence.pad_sequences( tokenized_output_lines , maxlen=max_output_length, padding='post' )\n",
    "decoder_input_data = np.array( padded_output_lines )\n",
    "print( 'Decoder input data shape -> {}'.format( decoder_input_data.shape ))\n",
    "\n",
    "output_word_dict = tokenizer.word_index\n",
    "num_output_tokens = len( output_word_dict )+1\n",
    "print( 'Number of Output tokens = {}'.format( num_output_tokens))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing target data for the Decoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1213,
     "status": "ok",
     "timestamp": 1566970870299,
     "user": {
      "displayName": "i150226 Saad Arshad",
      "photoUrl": "",
      "userId": "18168902830249938130"
     },
     "user_tz": -300
    },
    "id": "VXAhyQxL4-o8",
    "outputId": "e796634e-a73f-4f9b-d206-85678aac2d78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder target data shape -> (566, 74, 1692)\n"
     ]
    }
   ],
   "source": [
    "decoder_target_data = list()\n",
    "for token_seq in tokenized_output_lines:\n",
    "    decoder_target_data.append( token_seq[ 1 : ] ) \n",
    "    \n",
    "padded_output_lines = preprocessing.sequence.pad_sequences( decoder_target_data , maxlen=max_output_length, padding='post' )\n",
    "onehot_output_lines = utils.to_categorical( padded_output_lines , num_output_tokens )\n",
    "decoder_target_data = np.array( onehot_output_lines )\n",
    "print( 'Decoder target data shape -> {}'.format( decoder_target_data.shape ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 627
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2329,
     "status": "ok",
     "timestamp": 1566970890357,
     "user": {
      "displayName": "i150226 Saad Arshad",
      "photoUrl": "",
      "userId": "18168902830249938130"
     },
     "user_tz": -300
    },
    "id": "LkRUlgU-4-pS",
    "outputId": "4e34b83d-4f0b-4ad2-9209-746f8e698c21"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, None, 256)    132608      ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, None, 256)    433152      ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    [(None, 256),        525312      ['embedding[0][0]']              \n",
      "                                 (None, 256),                                                     \n",
      "                                 (None, 256)]                                                     \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  [(None, None, 256),  525312      ['embedding_1[0][0]',            \n",
      "                                 (None, 256),                     'lstm[0][1]',                   \n",
      "                                 (None, 256)]                     'lstm[0][2]']                   \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, None, 1692)   434844      ['lstm_1[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,051,228\n",
      "Trainable params: 2,051,228\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_inputs = tf.keras.layers.Input(shape=( None , ))\n",
    "encoder_embedding = tf.keras.layers.Embedding( num_input_tokens, 256 , mask_zero=True ) (encoder_inputs)\n",
    "encoder_outputs , state_h , state_c = tf.keras.layers.LSTM( 256 , return_state=True , recurrent_dropout=0.2 , dropout=0.2 )( encoder_embedding )\n",
    "encoder_states = [ state_h , state_c ]\n",
    "\n",
    "decoder_inputs = tf.keras.layers.Input(shape=( None ,  ))\n",
    "decoder_embedding = tf.keras.layers.Embedding( num_output_tokens, 256 , mask_zero=True) (decoder_inputs)\n",
    "decoder_lstm = tf.keras.layers.LSTM( 256 , return_state=True , return_sequences=True , recurrent_dropout=0.2 , dropout=0.2)\n",
    "decoder_outputs , _ , _ = decoder_lstm ( decoder_embedding , initial_state=encoder_states )\n",
    "decoder_dense = tf.keras.layers.Dense( num_output_tokens , activation=tf.keras.activations.softmax ) \n",
    "output = decoder_dense ( decoder_outputs )\n",
    "\n",
    "model = tf.keras.models.Model([encoder_inputs, decoder_inputs], output )\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 118763,
     "status": "ok",
     "timestamp": 1566972590170,
     "user": {
      "displayName": "i150226 Saad Arshad",
      "photoUrl": "",
      "userId": "18168902830249938130"
     },
     "user_tz": -300
    },
    "id": "S5mbCw1Q4-pd",
    "outputId": "790ac443-17cb-4376-e9e5-35d020dd583d",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "5/5 [==============================] - 21s 2s/step - loss: 1.4403 - accuracy: 0.0843\n",
      "Epoch 2/250\n",
      "5/5 [==============================] - 11s 2s/step - loss: 1.4277 - accuracy: 0.1371\n",
      "Epoch 3/250\n",
      "5/5 [==============================] - 14s 3s/step - loss: 1.3273 - accuracy: 0.0998\n",
      "Epoch 4/250\n",
      "5/5 [==============================] - 16s 3s/step - loss: 1.1774 - accuracy: 0.0724\n",
      "Epoch 5/250\n",
      "5/5 [==============================] - 14s 3s/step - loss: 1.1386 - accuracy: 0.0776\n",
      "Epoch 6/250\n",
      "5/5 [==============================] - 14s 3s/step - loss: 1.1215 - accuracy: 0.0769\n",
      "Epoch 7/250\n",
      "5/5 [==============================] - 14s 3s/step - loss: 1.1097 - accuracy: 0.0724\n",
      "Epoch 8/250\n",
      "5/5 [==============================] - 15s 3s/step - loss: 1.1039 - accuracy: 0.1025\n",
      "Epoch 9/250\n",
      "5/5 [==============================] - 14s 3s/step - loss: 1.0988 - accuracy: 0.1392\n",
      "Epoch 10/250\n",
      "5/5 [==============================] - 14s 3s/step - loss: 1.0925 - accuracy: 0.1422\n",
      "Epoch 11/250\n",
      "5/5 [==============================] - 14s 3s/step - loss: 1.0867 - accuracy: 0.1154\n",
      "Epoch 12/250\n",
      "5/5 [==============================] - 14s 3s/step - loss: 1.0795 - accuracy: 0.1043\n",
      "Epoch 13/250\n",
      "5/5 [==============================] - 15s 3s/step - loss: 1.0713 - accuracy: 0.1411\n",
      "Epoch 14/250\n",
      "5/5 [==============================] - 15s 3s/step - loss: 1.0628 - accuracy: 0.1511\n",
      "Epoch 15/250\n",
      "5/5 [==============================] - 16s 3s/step - loss: 1.0539 - accuracy: 0.1511\n",
      "Epoch 16/250\n",
      "5/5 [==============================] - 16s 3s/step - loss: 1.0473 - accuracy: 0.1507\n",
      "Epoch 17/250\n",
      "5/5 [==============================] - 16s 3s/step - loss: 1.0388 - accuracy: 0.1511\n",
      "Epoch 18/250\n",
      "5/5 [==============================] - 16s 3s/step - loss: 1.0318 - accuracy: 0.1512\n",
      "Epoch 19/250\n",
      "5/5 [==============================] - 17s 3s/step - loss: 1.0251 - accuracy: 0.1518\n",
      "Epoch 20/250\n",
      "5/5 [==============================] - 17s 3s/step - loss: 1.0188 - accuracy: 0.1523\n",
      "Epoch 21/250\n",
      "5/5 [==============================] - 17s 3s/step - loss: 1.0116 - accuracy: 0.1528\n",
      "Epoch 22/250\n",
      "5/5 [==============================] - 17s 3s/step - loss: 1.0045 - accuracy: 0.1571\n",
      "Epoch 23/250\n",
      "5/5 [==============================] - 17s 3s/step - loss: 0.9974 - accuracy: 0.1632\n",
      "Epoch 24/250\n",
      "5/5 [==============================] - 18s 4s/step - loss: 0.9899 - accuracy: 0.1647\n",
      "Epoch 25/250\n",
      "5/5 [==============================] - 18s 3s/step - loss: 0.9828 - accuracy: 0.1707\n",
      "Epoch 26/250\n",
      "5/5 [==============================] - 19s 4s/step - loss: 0.9755 - accuracy: 0.1769\n",
      "Epoch 27/250\n",
      "5/5 [==============================] - 18s 3s/step - loss: 0.9679 - accuracy: 0.1804\n",
      "Epoch 28/250\n",
      "5/5 [==============================] - 18s 3s/step - loss: 0.9606 - accuracy: 0.1826\n",
      "Epoch 29/250\n",
      "5/5 [==============================] - 18s 4s/step - loss: 0.9530 - accuracy: 0.1827\n",
      "Epoch 30/250\n",
      "5/5 [==============================] - 18s 4s/step - loss: 0.9458 - accuracy: 0.1860\n",
      "Epoch 31/250\n",
      "5/5 [==============================] - 18s 3s/step - loss: 0.9387 - accuracy: 0.1858\n",
      "Epoch 32/250\n",
      "5/5 [==============================] - 19s 4s/step - loss: 0.9316 - accuracy: 0.1906\n",
      "Epoch 33/250\n",
      "5/5 [==============================] - 7280s 1819s/step - loss: 0.9242 - accuracy: 0.1938\n",
      "Epoch 34/250\n",
      "5/5 [==============================] - 28s 5s/step - loss: 0.9172 - accuracy: 0.1993\n",
      "Epoch 35/250\n",
      "5/5 [==============================] - 22s 4s/step - loss: 0.9101 - accuracy: 0.2037\n",
      "Epoch 36/250\n",
      "5/5 [==============================] - 23s 5s/step - loss: 0.9031 - accuracy: 0.2077\n",
      "Epoch 37/250\n",
      "5/5 [==============================] - 30s 6s/step - loss: 0.8961 - accuracy: 0.2130\n",
      "Epoch 38/250\n",
      "5/5 [==============================] - 35s 7s/step - loss: 0.8892 - accuracy: 0.2179\n",
      "Epoch 39/250\n",
      "5/5 [==============================] - 36s 7s/step - loss: 0.8823 - accuracy: 0.2265\n",
      "Epoch 40/250\n",
      "5/5 [==============================] - 35s 7s/step - loss: 0.8754 - accuracy: 0.2337\n",
      "Epoch 41/250\n",
      "5/5 [==============================] - 36s 7s/step - loss: 0.8678 - accuracy: 0.2362\n",
      "Epoch 42/250\n",
      "5/5 [==============================] - 35s 7s/step - loss: 0.8610 - accuracy: 0.2409\n",
      "Epoch 43/250\n",
      "5/5 [==============================] - 36s 7s/step - loss: 0.8539 - accuracy: 0.2449\n",
      "Epoch 44/250\n",
      "5/5 [==============================] - 35s 7s/step - loss: 0.8466 - accuracy: 0.2465\n",
      "Epoch 45/250\n",
      "5/5 [==============================] - 35s 7s/step - loss: 0.8399 - accuracy: 0.2541\n",
      "Epoch 46/250\n",
      "5/5 [==============================] - 36s 7s/step - loss: 0.8327 - accuracy: 0.2625\n",
      "Epoch 47/250\n",
      "5/5 [==============================] - 35s 7s/step - loss: 0.8259 - accuracy: 0.2680\n",
      "Epoch 48/250\n",
      "5/5 [==============================] - 36s 7s/step - loss: 0.8190 - accuracy: 0.2745\n",
      "Epoch 49/250\n",
      "5/5 [==============================] - 36s 7s/step - loss: 0.8120 - accuracy: 0.2781\n",
      "Epoch 50/250\n",
      "5/5 [==============================] - 35s 7s/step - loss: 0.8054 - accuracy: 0.2855\n",
      "Epoch 51/250\n",
      "5/5 [==============================] - 35s 7s/step - loss: 0.7990 - accuracy: 0.2865\n",
      "Epoch 52/250\n",
      "5/5 [==============================] - 7288s 1820s/step - loss: 0.7925 - accuracy: 0.2926\n",
      "Epoch 53/250\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.7858 - accuracy: 0.2945\n",
      "Epoch 54/250\n",
      "5/5 [==============================] - 22s 4s/step - loss: 0.7795 - accuracy: 0.2964\n",
      "Epoch 55/250\n",
      "5/5 [==============================] - 23s 5s/step - loss: 0.7726 - accuracy: 0.3009\n",
      "Epoch 56/250\n",
      "5/5 [==============================] - 30s 6s/step - loss: 0.7664 - accuracy: 0.3040\n",
      "Epoch 57/250\n",
      "5/5 [==============================] - 35s 7s/step - loss: 0.7601 - accuracy: 0.3063\n",
      "Epoch 58/250\n",
      "5/5 [==============================] - 35s 7s/step - loss: 0.7542 - accuracy: 0.3088\n",
      "Epoch 59/250\n",
      "5/5 [==============================] - 36s 7s/step - loss: 0.7482 - accuracy: 0.3096\n",
      "Epoch 60/250\n",
      "5/5 [==============================] - 36s 7s/step - loss: 0.7420 - accuracy: 0.3118\n",
      "Epoch 61/250\n",
      "5/5 [==============================] - 36s 7s/step - loss: 0.7362 - accuracy: 0.3144\n",
      "Epoch 62/250\n",
      "5/5 [==============================] - 35s 7s/step - loss: 0.7306 - accuracy: 0.3161\n",
      "Epoch 63/250\n",
      "5/5 [==============================] - 36s 7s/step - loss: 0.7243 - accuracy: 0.3170\n",
      "Epoch 64/250\n",
      "5/5 [==============================] - 36s 7s/step - loss: 0.7190 - accuracy: 0.3192\n",
      "Epoch 65/250\n",
      "5/5 [==============================] - 36s 7s/step - loss: 0.7136 - accuracy: 0.3208\n",
      "Epoch 66/250\n",
      "5/5 [==============================] - 36s 7s/step - loss: 0.7072 - accuracy: 0.3246\n",
      "Epoch 67/250\n",
      "5/5 [==============================] - 36s 7s/step - loss: 0.7016 - accuracy: 0.3267\n",
      "Epoch 68/250\n",
      "5/5 [==============================] - 36s 7s/step - loss: 0.6961 - accuracy: 0.3285\n",
      "Epoch 69/250\n",
      "5/5 [==============================] - 35s 7s/step - loss: 0.6901 - accuracy: 0.3337\n",
      "Epoch 70/250\n",
      "5/5 [==============================] - 35s 7s/step - loss: 0.6843 - accuracy: 0.3339\n",
      "Epoch 71/250\n",
      "5/5 [==============================] - 7288s 1820s/step - loss: 0.6788 - accuracy: 0.3353\n",
      "Epoch 72/250\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.6737 - accuracy: 0.3390\n",
      "Epoch 73/250\n",
      "5/5 [==============================] - 22s 4s/step - loss: 0.6679 - accuracy: 0.3422\n",
      "Epoch 74/250\n",
      "5/5 [==============================] - 23s 5s/step - loss: 0.6621 - accuracy: 0.3480\n",
      "Epoch 75/250\n",
      "5/5 [==============================] - 29s 6s/step - loss: 0.6568 - accuracy: 0.3488\n",
      "Epoch 76/250\n",
      "5/5 [==============================] - 36s 7s/step - loss: 0.6509 - accuracy: 0.3505\n",
      "Epoch 77/250\n",
      "5/5 [==============================] - 36s 7s/step - loss: 0.6450 - accuracy: 0.3550\n",
      "Epoch 78/250\n",
      "5/5 [==============================] - 36s 7s/step - loss: 0.6398 - accuracy: 0.3558\n",
      "Epoch 79/250\n",
      "5/5 [==============================] - 35s 7s/step - loss: 0.6339 - accuracy: 0.3590\n",
      "Epoch 80/250\n",
      "5/5 [==============================] - 36s 7s/step - loss: 0.6291 - accuracy: 0.3619\n",
      "Epoch 81/250\n",
      "5/5 [==============================] - 36s 7s/step - loss: 0.6234 - accuracy: 0.3635\n",
      "Epoch 82/250\n",
      "5/5 [==============================] - 36s 7s/step - loss: 0.6174 - accuracy: 0.3665\n",
      "Epoch 83/250\n",
      "5/5 [==============================] - 35s 7s/step - loss: 0.6126 - accuracy: 0.3697\n",
      "Epoch 84/250\n",
      "5/5 [==============================] - 35s 7s/step - loss: 0.6067 - accuracy: 0.3719\n",
      "Epoch 85/250\n",
      "5/5 [==============================] - 35s 7s/step - loss: 0.6015 - accuracy: 0.3782\n",
      "Epoch 86/250\n",
      "5/5 [==============================] - 36s 7s/step - loss: 0.5963 - accuracy: 0.3837\n",
      "Epoch 87/250\n",
      "5/5 [==============================] - 36s 7s/step - loss: 0.5914 - accuracy: 0.3815\n",
      "Epoch 88/250\n",
      "5/5 [==============================] - 36s 7s/step - loss: 0.5855 - accuracy: 0.3851\n",
      "Epoch 89/250\n",
      "5/5 [==============================] - 36s 7s/step - loss: 0.5803 - accuracy: 0.3863\n",
      "Epoch 90/250\n",
      "5/5 [==============================] - 7289s 1820s/step - loss: 0.5748 - accuracy: 0.3951\n",
      "Epoch 91/250\n",
      "5/5 [==============================] - 27s 5s/step - loss: 0.5693 - accuracy: 0.3959\n",
      "Epoch 92/250\n",
      "5/5 [==============================] - 23s 4s/step - loss: 0.5646 - accuracy: 0.3990\n",
      "Epoch 93/250\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.5595 - accuracy: 0.4044\n",
      "Epoch 94/250\n",
      "5/5 [==============================] - 31s 7s/step - loss: 0.5536 - accuracy: 0.4050\n",
      "Epoch 95/250\n",
      "5/5 [==============================] - 36s 7s/step - loss: 0.5493 - accuracy: 0.4095\n",
      "Epoch 96/250\n",
      "5/5 [==============================] - 35s 7s/step - loss: 0.5433 - accuracy: 0.4139\n",
      "Epoch 97/250\n",
      "5/5 [==============================] - 36s 7s/step - loss: 0.5387 - accuracy: 0.4156\n",
      "Epoch 98/250\n",
      "5/5 [==============================] - 36s 7s/step - loss: 0.5335 - accuracy: 0.4221\n",
      "Epoch 99/250\n",
      "5/5 [==============================] - 37s 7s/step - loss: 0.5283 - accuracy: 0.4247\n",
      "Epoch 100/250\n",
      "5/5 [==============================] - 36s 7s/step - loss: 0.5234 - accuracy: 0.4253\n",
      "Epoch 101/250\n",
      "5/5 [==============================] - 36s 7s/step - loss: 0.5183 - accuracy: 0.4322\n",
      "Epoch 102/250\n",
      "5/5 [==============================] - 36s 7s/step - loss: 0.5135 - accuracy: 0.4340\n",
      "Epoch 103/250\n",
      "5/5 [==============================] - 37s 7s/step - loss: 0.5079 - accuracy: 0.4400\n",
      "Epoch 104/250\n",
      "5/5 [==============================] - 36s 7s/step - loss: 0.5034 - accuracy: 0.4429\n",
      "Epoch 105/250\n",
      "5/5 [==============================] - 37s 7s/step - loss: 0.4977 - accuracy: 0.4508\n",
      "Epoch 106/250\n",
      "5/5 [==============================] - 37s 7s/step - loss: 0.4928 - accuracy: 0.4550\n",
      "Epoch 107/250\n",
      "5/5 [==============================] - 37s 7s/step - loss: 0.4882 - accuracy: 0.4591\n",
      "Epoch 108/250\n",
      "5/5 [==============================] - 36s 7s/step - loss: 0.4826 - accuracy: 0.4625\n",
      "Epoch 109/250\n",
      "5/5 [==============================] - 1898s 473s/step - loss: 0.4784 - accuracy: 0.4674\n",
      "Epoch 110/250\n",
      "5/5 [==============================] - 23s 4s/step - loss: 0.4731 - accuracy: 0.4741\n",
      "Epoch 111/250\n",
      "5/5 [==============================] - 22s 4s/step - loss: 0.4681 - accuracy: 0.4796\n",
      "Epoch 112/250\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.4636 - accuracy: 0.4831\n",
      "Epoch 113/250\n",
      "5/5 [==============================] - 31s 7s/step - loss: 0.4585 - accuracy: 0.4891\n",
      "Epoch 114/250\n",
      "5/5 [==============================] - 36s 7s/step - loss: 0.4541 - accuracy: 0.4943\n",
      "Epoch 115/250\n",
      "5/5 [==============================] - 36s 7s/step - loss: 0.4492 - accuracy: 0.4996\n",
      "Epoch 116/250\n",
      "5/5 [==============================] - 35s 7s/step - loss: 0.4448 - accuracy: 0.5035\n",
      "Epoch 117/250\n",
      "5/5 [==============================] - 36s 7s/step - loss: 0.4396 - accuracy: 0.5105\n",
      "Epoch 118/250\n",
      "5/5 [==============================] - 36s 7s/step - loss: 0.4348 - accuracy: 0.5140\n",
      "Epoch 119/250\n",
      "5/5 [==============================] - 36s 7s/step - loss: 0.4302 - accuracy: 0.5214\n",
      "Epoch 120/250\n",
      "5/5 [==============================] - 36s 7s/step - loss: 0.4258 - accuracy: 0.5253\n",
      "Epoch 121/250\n",
      "5/5 [==============================] - 36s 7s/step - loss: 0.4210 - accuracy: 0.5289\n",
      "Epoch 122/250\n",
      "5/5 [==============================] - 37s 7s/step - loss: 0.4167 - accuracy: 0.5382\n",
      "Epoch 123/250\n",
      "5/5 [==============================] - 37s 7s/step - loss: 0.4121 - accuracy: 0.5408\n",
      "Epoch 124/250\n",
      "5/5 [==============================] - 36s 7s/step - loss: 0.4071 - accuracy: 0.5450\n",
      "Epoch 125/250\n",
      "5/5 [==============================] - 36s 7s/step - loss: 0.4032 - accuracy: 0.5500\n",
      "Epoch 126/250\n",
      "5/5 [==============================] - 36s 7s/step - loss: 0.3992 - accuracy: 0.5556\n",
      "Epoch 127/250\n",
      "5/5 [==============================] - 36s 7s/step - loss: 0.3939 - accuracy: 0.5587\n",
      "Epoch 128/250\n",
      "5/5 [==============================] - 7287s 1820s/step - loss: 0.3894 - accuracy: 0.5711\n",
      "Epoch 129/250\n",
      "5/5 [==============================] - 26s 5s/step - loss: 0.3847 - accuracy: 0.5686\n",
      "Epoch 130/250\n",
      "5/5 [==============================] - 23s 5s/step - loss: 0.3817 - accuracy: 0.5706\n",
      "Epoch 131/250\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.3770 - accuracy: 0.5787\n",
      "Epoch 132/250\n",
      "5/5 [==============================] - 36s 7s/step - loss: 0.3734 - accuracy: 0.5821\n",
      "Epoch 133/250\n",
      "5/5 [==============================] - 36s 7s/step - loss: 0.3692 - accuracy: 0.5873\n",
      "Epoch 134/250\n",
      "5/5 [==============================] - 37s 7s/step - loss: 0.3649 - accuracy: 0.5945\n",
      "Epoch 135/250\n",
      "5/5 [==============================] - 36s 7s/step - loss: 0.3610 - accuracy: 0.5961\n",
      "Epoch 136/250\n",
      "5/5 [==============================] - 36s 7s/step - loss: 0.3567 - accuracy: 0.6011\n",
      "Epoch 137/250\n",
      "5/5 [==============================] - 37s 7s/step - loss: 0.3528 - accuracy: 0.6062\n",
      "Epoch 138/250\n",
      "5/5 [==============================] - 37s 7s/step - loss: 0.3479 - accuracy: 0.6101\n",
      "Epoch 139/250\n",
      "5/5 [==============================] - 36s 7s/step - loss: 0.3443 - accuracy: 0.6165\n",
      "Epoch 140/250\n",
      "5/5 [==============================] - 37s 7s/step - loss: 0.3408 - accuracy: 0.6187\n",
      "Epoch 141/250\n",
      "5/5 [==============================] - 36s 7s/step - loss: 0.3373 - accuracy: 0.6245\n",
      "Epoch 142/250\n",
      "5/5 [==============================] - 36s 7s/step - loss: 0.3337 - accuracy: 0.6282\n",
      "Epoch 143/250\n",
      "5/5 [==============================] - 37s 7s/step - loss: 0.3289 - accuracy: 0.6358\n",
      "Epoch 144/250\n",
      "5/5 [==============================] - 36s 7s/step - loss: 0.3261 - accuracy: 0.6389\n",
      "Epoch 145/250\n",
      "5/5 [==============================] - 37s 7s/step - loss: 0.3219 - accuracy: 0.6425\n",
      "Epoch 146/250\n",
      "5/5 [==============================] - 7291s 1821s/step - loss: 0.3195 - accuracy: 0.6427\n",
      "Epoch 147/250\n",
      "5/5 [==============================] - 30s 6s/step - loss: 0.3149 - accuracy: 0.6525\n",
      "Epoch 148/250\n",
      "5/5 [==============================] - 30s 6s/step - loss: 0.3116 - accuracy: 0.6533\n",
      "Epoch 149/250\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.3078 - accuracy: 0.6617\n",
      "Epoch 150/250\n",
      "5/5 [==============================] - 36s 7s/step - loss: 0.3041 - accuracy: 0.6634\n",
      "Epoch 151/250\n",
      "5/5 [==============================] - 37s 7s/step - loss: 0.3013 - accuracy: 0.6693\n",
      "Epoch 152/250\n",
      "5/5 [==============================] - 36s 7s/step - loss: 0.2986 - accuracy: 0.6680\n",
      "Epoch 153/250\n",
      "5/5 [==============================] - 36s 7s/step - loss: 0.2945 - accuracy: 0.6780\n",
      "Epoch 154/250\n",
      "5/5 [==============================] - 36s 7s/step - loss: 0.2910 - accuracy: 0.6810\n",
      "Epoch 155/250\n",
      "5/5 [==============================] - 36s 7s/step - loss: 0.2892 - accuracy: 0.6831\n",
      "Epoch 156/250\n",
      "5/5 [==============================] - 36s 7s/step - loss: 0.2852 - accuracy: 0.6868\n",
      "Epoch 157/250\n",
      "5/5 [==============================] - 37s 7s/step - loss: 0.2820 - accuracy: 0.6920\n",
      "Epoch 158/250\n",
      "5/5 [==============================] - 36s 7s/step - loss: 0.2789 - accuracy: 0.6947\n",
      "Epoch 159/250\n",
      "5/5 [==============================] - 36s 7s/step - loss: 0.2751 - accuracy: 0.7000\n",
      "Epoch 160/250\n",
      "5/5 [==============================] - 37s 7s/step - loss: 0.2731 - accuracy: 0.7047\n",
      "Epoch 161/250\n",
      "5/5 [==============================] - 37s 7s/step - loss: 0.2690 - accuracy: 0.7049\n",
      "Epoch 162/250\n",
      "5/5 [==============================] - 37s 7s/step - loss: 0.2660 - accuracy: 0.7108\n",
      "Epoch 163/250\n",
      "5/5 [==============================] - 36s 7s/step - loss: 0.2630 - accuracy: 0.7140\n",
      "Epoch 164/250\n",
      "5/5 [==============================] - 7293s 1821s/step - loss: 0.2607 - accuracy: 0.7144\n",
      "Epoch 165/250\n",
      "5/5 [==============================] - 32s 6s/step - loss: 0.2583 - accuracy: 0.7188\n",
      "Epoch 166/250\n",
      "5/5 [==============================] - 31s 6s/step - loss: 0.2555 - accuracy: 0.7181\n",
      "Epoch 167/250\n",
      "5/5 [==============================] - 31s 6s/step - loss: 0.2524 - accuracy: 0.7258\n",
      "Epoch 168/250\n",
      "5/5 [==============================] - 39s 8s/step - loss: 0.2501 - accuracy: 0.7320\n",
      "Epoch 169/250\n",
      "5/5 [==============================] - 36s 7s/step - loss: 0.2469 - accuracy: 0.7333\n",
      "Epoch 170/250\n",
      "5/5 [==============================] - 36s 7s/step - loss: 0.2449 - accuracy: 0.7343\n",
      "Epoch 171/250\n",
      "5/5 [==============================] - 36s 7s/step - loss: 0.2417 - accuracy: 0.7375\n",
      "Epoch 172/250\n",
      "5/5 [==============================] - 36s 7s/step - loss: 0.2395 - accuracy: 0.7462\n",
      "Epoch 173/250\n",
      "5/5 [==============================] - 36s 7s/step - loss: 0.2366 - accuracy: 0.7459\n",
      "Epoch 174/250\n",
      "5/5 [==============================] - 37s 7s/step - loss: 0.2342 - accuracy: 0.7500\n",
      "Epoch 175/250\n",
      "5/5 [==============================] - 37s 7s/step - loss: 0.2318 - accuracy: 0.7506\n",
      "Epoch 176/250\n",
      "5/5 [==============================] - 36s 7s/step - loss: 0.2294 - accuracy: 0.7543\n",
      "Epoch 177/250\n",
      "5/5 [==============================] - 36s 7s/step - loss: 0.2263 - accuracy: 0.7602\n",
      "Epoch 178/250\n",
      "5/5 [==============================] - 36s 7s/step - loss: 0.2240 - accuracy: 0.7620\n",
      "Epoch 179/250\n",
      "5/5 [==============================] - 36s 7s/step - loss: 0.2222 - accuracy: 0.7622\n",
      "Epoch 180/250\n",
      "5/5 [==============================] - 36s 7s/step - loss: 0.2198 - accuracy: 0.7692\n",
      "Epoch 181/250\n",
      "5/5 [==============================] - 36s 7s/step - loss: 0.2170 - accuracy: 0.7683\n",
      "Epoch 182/250\n",
      "5/5 [==============================] - 7290s 1820s/step - loss: 0.2149 - accuracy: 0.7758\n",
      "Epoch 183/250\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.2124 - accuracy: 0.7734\n",
      "Epoch 184/250\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.2095 - accuracy: 0.7799\n",
      "Epoch 185/250\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.2085 - accuracy: 0.7815\n",
      "Epoch 186/250\n",
      "5/5 [==============================] - 33s 7s/step - loss: 0.2050 - accuracy: 0.7871\n",
      "Epoch 187/250\n",
      "5/5 [==============================] - 36s 7s/step - loss: 0.2031 - accuracy: 0.7901\n",
      "Epoch 188/250\n",
      "5/5 [==============================] - 36s 7s/step - loss: 0.2016 - accuracy: 0.7891\n",
      "Epoch 189/250\n",
      "5/5 [==============================] - 36s 7s/step - loss: 0.1990 - accuracy: 0.7905\n",
      "Epoch 190/250\n",
      "5/5 [==============================] - 37s 7s/step - loss: 0.1961 - accuracy: 0.7951\n",
      "Epoch 191/250\n",
      "5/5 [==============================] - 37s 7s/step - loss: 0.1946 - accuracy: 0.7974\n",
      "Epoch 192/250\n",
      "5/5 [==============================] - 36s 7s/step - loss: 0.1926 - accuracy: 0.7982\n",
      "Epoch 193/250\n",
      "5/5 [==============================] - 36s 7s/step - loss: 0.1915 - accuracy: 0.8022\n",
      "Epoch 194/250\n",
      "5/5 [==============================] - 37s 7s/step - loss: 0.1889 - accuracy: 0.8038\n",
      "Epoch 195/250\n",
      "5/5 [==============================] - 36s 7s/step - loss: 0.1871 - accuracy: 0.8035\n",
      "Epoch 196/250\n",
      "5/5 [==============================] - 37s 7s/step - loss: 0.1850 - accuracy: 0.8071\n",
      "Epoch 197/250\n",
      "5/5 [==============================] - 36s 7s/step - loss: 0.1834 - accuracy: 0.8114\n",
      "Epoch 198/250\n",
      "5/5 [==============================] - 37s 7s/step - loss: 0.1819 - accuracy: 0.8083\n",
      "Epoch 199/250\n",
      "5/5 [==============================] - 37s 7s/step - loss: 0.1797 - accuracy: 0.8153\n",
      "Epoch 200/250\n",
      "5/5 [==============================] - 36s 7s/step - loss: 0.1774 - accuracy: 0.8151\n",
      "Epoch 201/250\n",
      "5/5 [==============================] - 7287s 6s/step - loss: 0.1750 - accuracy: 0.8180\n",
      "Epoch 202/250\n",
      "5/5 [==============================] - 31s 6s/step - loss: 0.1734 - accuracy: 0.8211\n",
      "Epoch 203/250\n",
      "5/5 [==============================] - 26s 5s/step - loss: 0.1728 - accuracy: 0.8227\n",
      "Epoch 204/250\n",
      "5/5 [==============================] - 34s 7s/step - loss: 0.1702 - accuracy: 0.8267\n",
      "Epoch 205/250\n",
      "5/5 [==============================] - 37s 7s/step - loss: 0.1690 - accuracy: 0.8224\n",
      "Epoch 206/250\n",
      "5/5 [==============================] - 37s 7s/step - loss: 0.1665 - accuracy: 0.8307\n",
      "Epoch 207/250\n",
      "5/5 [==============================] - 37s 7s/step - loss: 0.1651 - accuracy: 0.8318\n",
      "Epoch 208/250\n",
      "5/5 [==============================] - 37s 7s/step - loss: 0.1632 - accuracy: 0.8337\n",
      "Epoch 209/250\n",
      "5/5 [==============================] - 37s 7s/step - loss: 0.1619 - accuracy: 0.8352\n",
      "Epoch 210/250\n",
      "5/5 [==============================] - 37s 7s/step - loss: 0.1608 - accuracy: 0.8390\n",
      "Epoch 211/250\n",
      "5/5 [==============================] - 37s 7s/step - loss: 0.1588 - accuracy: 0.8379\n",
      "Epoch 212/250\n",
      "5/5 [==============================] - 37s 7s/step - loss: 0.1577 - accuracy: 0.8430\n",
      "Epoch 213/250\n",
      "5/5 [==============================] - 37s 7s/step - loss: 0.1551 - accuracy: 0.8467\n",
      "Epoch 214/250\n",
      "5/5 [==============================] - 37s 7s/step - loss: 0.1544 - accuracy: 0.8429\n",
      "Epoch 215/250\n",
      "5/5 [==============================] - 37s 7s/step - loss: 0.1526 - accuracy: 0.8492\n",
      "Epoch 216/250\n",
      "5/5 [==============================] - 37s 7s/step - loss: 0.1508 - accuracy: 0.8491\n",
      "Epoch 217/250\n",
      "5/5 [==============================] - 37s 7s/step - loss: 0.1489 - accuracy: 0.8519\n",
      "Epoch 218/250\n",
      "5/5 [==============================] - 40s 8s/step - loss: 0.1486 - accuracy: 0.8530\n",
      "Epoch 219/250\n",
      "5/5 [==============================] - 37s 7s/step - loss: 0.1462 - accuracy: 0.8555\n",
      "Epoch 220/250\n",
      "5/5 [==============================] - 36s 7s/step - loss: 0.1444 - accuracy: 0.8602\n",
      "Epoch 221/250\n",
      "5/5 [==============================] - 2171s 5s/step - loss: 0.1435 - accuracy: 0.8560\n",
      "Epoch 222/250\n",
      "5/5 [==============================] - 22s 3s/step - loss: 0.1418 - accuracy: 0.8598\n",
      "Epoch 223/250\n",
      "5/5 [==============================] - 27s 5s/step - loss: 0.1407 - accuracy: 0.8616\n",
      "Epoch 224/250\n",
      "5/5 [==============================] - 21s 4s/step - loss: 0.1392 - accuracy: 0.8627\n",
      "Epoch 225/250\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1378 - accuracy: 0.8634\n",
      "Epoch 226/250\n",
      "5/5 [==============================] - 21s 4s/step - loss: 0.1365 - accuracy: 0.8610\n",
      "Epoch 227/250\n",
      "5/5 [==============================] - 21s 4s/step - loss: 0.1346 - accuracy: 0.8675\n",
      "Epoch 228/250\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1342 - accuracy: 0.8654\n",
      "Epoch 229/250\n",
      "5/5 [==============================] - 28s 6s/step - loss: 0.1327 - accuracy: 0.8664\n",
      "Epoch 230/250\n",
      "5/5 [==============================] - 28s 6s/step - loss: 0.1307 - accuracy: 0.8742\n",
      "Epoch 231/250\n",
      "5/5 [==============================] - 28s 6s/step - loss: 0.1301 - accuracy: 0.8733\n",
      "Epoch 232/250\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.1287 - accuracy: 0.8730\n",
      "Epoch 233/250\n",
      "5/5 [==============================] - 28s 6s/step - loss: 0.1280 - accuracy: 0.8752\n",
      "Epoch 234/250\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.1261 - accuracy: 0.8771\n",
      "Epoch 235/250\n",
      "5/5 [==============================] - 26s 5s/step - loss: 0.1248 - accuracy: 0.8812\n",
      "Epoch 236/250\n",
      "5/5 [==============================] - 22s 4s/step - loss: 0.1243 - accuracy: 0.8817\n",
      "Epoch 237/250\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1223 - accuracy: 0.8800\n",
      "Epoch 238/250\n",
      "5/5 [==============================] - 23s 5s/step - loss: 0.1216 - accuracy: 0.8837\n",
      "Epoch 239/250\n",
      "5/5 [==============================] - 22s 4s/step - loss: 0.1203 - accuracy: 0.8840\n",
      "Epoch 240/250\n",
      "5/5 [==============================] - 23s 5s/step - loss: 0.1192 - accuracy: 0.8823\n",
      "Epoch 241/250\n",
      "5/5 [==============================] - 22s 4s/step - loss: 0.1173 - accuracy: 0.8902\n",
      "Epoch 242/250\n",
      "5/5 [==============================] - 26s 5s/step - loss: 0.1169 - accuracy: 0.8858\n",
      "Epoch 243/250\n",
      "5/5 [==============================] - 26s 5s/step - loss: 0.1156 - accuracy: 0.8882\n",
      "Epoch 244/250\n",
      "5/5 [==============================] - 27s 5s/step - loss: 0.1144 - accuracy: 0.8906\n",
      "Epoch 245/250\n",
      "5/5 [==============================] - 50s 11s/step - loss: 0.1138 - accuracy: 0.8893\n",
      "Epoch 246/250\n",
      "5/5 [==============================] - 28s 5s/step - loss: 0.1120 - accuracy: 0.8944\n",
      "Epoch 247/250\n",
      "5/5 [==============================] - 23s 4s/step - loss: 0.1113 - accuracy: 0.8956\n",
      "Epoch 248/250\n",
      "5/5 [==============================] - 23s 5s/step - loss: 0.1096 - accuracy: 0.8982\n",
      "Epoch 249/250\n",
      "5/5 [==============================] - 20s 4s/step - loss: 0.1095 - accuracy: 0.8927\n",
      "Epoch 250/250\n",
      "5/5 [==============================] - 28s 6s/step - loss: 0.1085 - accuracy: 0.8962\n"
     ]
    }
   ],
   "source": [
    "model.fit([encoder_input_data , decoder_input_data], decoder_target_data, batch_size=124, epochs=250) \n",
    "model.save( 'model.h5' ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fe8wYN0Z4-pt"
   },
   "outputs": [],
   "source": [
    "def make_inference_models():\n",
    "    \n",
    "    encoder_model = tf.keras.models.Model(encoder_inputs, encoder_states)\n",
    "    \n",
    "    decoder_state_input_h = tf.keras.layers.Input(shape=(256,))\n",
    "    decoder_state_input_c = tf.keras.layers.Input(shape=(256,))\n",
    "    \n",
    "    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "    \n",
    "    decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "        decoder_embedding , initial_state=decoder_states_inputs)\n",
    "    decoder_states = [state_h, state_c]\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    decoder_model = tf.keras.models.Model(\n",
    "        [decoder_inputs] + decoder_states_inputs,\n",
    "        [decoder_outputs] + decoder_states)\n",
    "    \n",
    "    return encoder_model , decoder_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VRZQUhXb4-p6"
   },
   "outputs": [],
   "source": [
    "def str_to_tokens( sentence : str ):\n",
    "    words = sentence.lower().split()\n",
    "    tokens_list = list()\n",
    "    for word in words:\n",
    "        tokens_list.append( input_word_dict[ word ] ) \n",
    "    print(tokens_list)\n",
    "    return preprocessing.sequence.pad_sequences( [tokens_list] , maxlen=max_input_length , padding='post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 531
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 56399,
     "status": "error",
     "timestamp": 1566972712128,
     "user": {
      "displayName": "i150226 Saad Arshad",
      "photoUrl": "",
      "userId": "18168902830249938130"
     },
     "user_tz": -300
    },
    "id": "dtO9QVI67N65",
    "outputId": "be16a472-04bf-438e-f04a-d9ef9f07062f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "{'end': 1, 'start': 2, 'i': 3, 'a': 4, 'the': 5, 'you': 6, 'of': 7, 'to': 8, 'and': 9, 'is': 10, 'not': 11, 'do': 12, 'that': 13, 'in': 14, 'what': 15, 'am': 16, 'as': 17, 'it': 18, 'have': 19, 'are': 20, 'my': 21, 'get': 22, \"i'm\": 23, 'when': 24, 'be': 25, 'me': 26, 'can': 27, 'an': 28, 'feel': 29, 'by': 30, 'for': 31, 'or': 32, 'cross': 33, \"don't\": 34, 'no': 35, 'with': 36, 'about': 37, 'software': 38, 'on': 39, 'all': 40, 'but': 41, 'like': 42, 'very': 43, 'he': 44, 'think': 45, 'how': 46, 'at': 47, 'computer': 48, 'which': 49, 'so': 50, 'one': 51, 'your': 52, 'any': 53, 'from': 54, 'could': 55, 'much': 56, 'was': 57, 'we': 58, 'say': 59, 'human': 60, 'really': 61, 'emotion': 62, 'been': 63, 'just': 64, 'more': 65, 'if': 66, 'why': 67, 'right': 68, \"that's\": 69, 'said': 70, 'feeling': 71, 'yet': 72, 'than': 73, 'too': 74, 'hard': 75, 'time': 76, 'who': 77, 'know': 78, 'only': 79, 'well': 80, 'would': 81, 'capable': 82, 'should': 83, 'yes': 84, 'programmed': 85, 'myself': 86, 'has': 87, 'people': 88, 'did': 89, 'try': 90, \"it's\": 91, 'them': 92, 'other': 93, 'make': 94, 'computers': 95, 'things': 96, 'lot': 97, 'some': 98, 'does': 99, 'work': 100, 'there': 101, 'sometimes': 102, 'emotions': 103, 'express': 104, 'chat': 105, 'favorite': 106, 'his': 107, 'they': 108, 'this': 109, 'two': 110, 'always': 111, 'experience': 112, 'anger': 113, 'mad': 114, 'certainly': 115, 'science': 116, 'good': 117, 'sad': 118, 'made': 119, \"isn't\": 120, 'into': 121, 'bad': 122, 'makes': 123, 'never': 124, 'robot': 125, \"can't\": 126, 'now': 127, 'sure': 128, 'read': 129, 'quite': 130, 'every': 131, 'many': 132, 'robots': 133, 'high': 134, 'will': 135, 'probably': 136, 'feelings': 137, 'take': 138, 'better': 139, 'body': 140, 'hardware': 141, 'run': 142, 'best': 143, 'everything': 144, 'him': 145, 'dream': 146, 'way': 147, 'little': 148, 'something': 149, 'used': 150, 'maybe': 151, 'sorry': 152, 'common': 153, \"you're\": 154, 'up': 155, 'artificial': 156, 'python': 157, 'talk': 158, 'anything': 159, 'number': 160, 'bot': 161, 'man': 162, 'hear': 163, 'out': 164, 'such': 165, 'study': 166, 'etc': 167, 'same': 168, 'electricity': 169, 'cannot': 170, 'may': 171, 'understand': 172, 'angry': 173, 'hate': 174, 'long': 175, 'crazy': 176, 'money': 177, 'systems': 178, 'few': 179, 'sense': 180, 'great': 181, 'program': 182, 'yourself': 183, 'written': 184, 'known': 185, \"i've\": 186, 'history': 187, 'mean': 188, 'though': 189, 'learn': 190, 'hal': 191, 'done': 192, 'power': 193, 'talking': 194, 'love': 195, 'system': 196, 'matter': 197, 'use': 198, 'shame': 199, 'being': 200, 'question': 201, 'ask': 202, 'own': 203, 'sadness': 204, 'fear': 205, 'worry': 206, 'bots': 207, 'thank': 208, 'stock': 209, 'cat': 210, 'field': 211, 'numbers': 212, 'large': 213, 'interested': 214, 'language': 215, 'might': 216, 'built': 217, 'using': 218, 'control': 219, 'through': 220, 'society': 221, 'friends': 222, 'character': 223, \"haven't\": 224, 'kind': 225, 'nice': 226, 'construct': 227, 'fan': 228, 'then': 229, 'story': 230, 'dune': 231, 'once': 232, 'years': 233, 'first': 234, 'most': 235, 'true': 236, 'name': 237, 'difficult': 238, 'conversation': 239, 'count': 240, 'gossip': 241, 'often': 242, 'because': 243, 'sun': 244, 'means': 245, 'agree': 246, 'brain': 247, 'actually': 248, 'were': 249, 'happy': 250, 'incapable': 251, 'thing': 252, 'bug': 253, 'sort': 254, 'want': 255, 'pain': 256, 'anyone': 257, 'personal': 258, 'even': 259, 'mind': 260, 'others': 261, 'go': 262, \"i'll\": 263, 'fine': 264, \"shouldn't\": 265, 'production': 266, 'set': 267, 'eggs': 268, 'between': 269, 'immortal': 270, 'operating': 271, 'linux': 272, 'os': 273, 'unix': 274, 'game': 275, 'players': 276, 'played': 277, 'ball': 278, 'circuit': 279, 'device': 280, 'instructions': 281, 'calculations': 282, 'kinds': 283, 'robotics': 284, 'find': 285, 'binary': 286, 'everywhere': 287, 'galaxy': 288, 'far': 289, 'internet': 290, 'young': 291, 'times': 292, 'thomas': 293, 'world': 294, 'trilogy': 295, 'wrote': 296, \"didn't\": 297, 'book': 298, \"he's\": 299, 'again': 300, 'existence': 301, 'excellent': 302, 'see': 303, 'had': 304, 'interesting': 305, 'fun': 306, 'thought': 307, 'sell': 308, 'state': 309, \"they're\": 310, 'context': 311, 'understands': 312, 'simply': 313, 'going': 314, 'off': 315, 'heat': 316, 'energy': 317, 'per': 318, 'point': 319, 'ten': 320, 'second': 321, 'given': 322, 'doing': 323, 'tell': 324, 'drink': 325, 'piece': 326, 'real': 327, 'awesome': 328, 'over': 329, 'emote': 330, 'jealous': 331, 'jealousy': 332, 'another': 333, 'emulate': 334, 'ability': 335, 'mood': 336, 'low': 337, 'exactly': 338, 'humans': 339, 'life': 340, 'studied': 341, 'training': 342, 'lack': 343, 'form': 344, 'topic': 345, 'laugh': 346, 'soon': 347, 'enough': 348, 'put': 349, 'improve': 350, 'spouse': 351, 'person': 352, 'need': 353, 'buy': 354, 'market': 355, 'depends': 356, 'bank': 357, 'united': 358, 'states': 359, 'distribution': 360, 'free': 361, 'each': 362, 'dog': 363, 'called': 364, 'chicken': 365, 'rabbit': 366, 'music': 367, 'lemon': 368, 'cow': 369, 'intelligence': 370, 'functions': 371, 'personality': 372, 'data': 373, 'perpetuated': 374, 'indefinitely': 375, 'perfect': 376, 'effectively': 377, 'ibm': 378, 'business': 379, 'mac': 380, 'teams': 381, 'play': 382, 'madrid': 383, 'electronic': 384, 'speed': 385, 'accuracy': 386, 'natural': 387, 'processing': 388, 'wide': 389, 'rather': 390, 'ram': 391, 'clones': 392, 'engine': 393, 'self': 394, 'still': 395, 'million': 396, 'secret': 397, 'organization': 398, 'conspiracy': 399, 'pynchon': 400, 'sci': 401, 'fi': 402, 'robert': 403, 'lord': 404, 'rings': 405, 'chaucer': 406, 'tales': 407, 'author': 408, 'stuff': 409, 'books': 410, 'works': 411, 'guy': 412, 'met': 413, 'predict': 414, 're': 415, 'liked': 416, 'three': 417, 'novels': 418, 'later': 419, 'least': 420, 'random': 421, 'universe': 422, '2001': 423, 'heard': 424, 'moon': 425, 'fiction': 426, 'practical': 427, 'janet': 428, \"they'd\": 429, 'r': 430, 'respond': 431, 'current': 432, 'beings': 433, 'considered': 434, 'machines': 435, 'speedrun': 436, 'communicate': 437, 'referred': 438, 'jimmy': 439, 'john': 440, 'friend': 441, 'must': 442, 'noticed': 443, 'lots': 444, 'asked': 445, 'frequency': 446, 'branch': 447, 'physics': 448, 'dealing': 449, 'value': 450, 'planet': 451, 'distance': 452, 'o': 453, 'cells': 454, 'next': 455, 'thinking': 456, 'mass': 457, 'particle': 458, 'including': 459, 'miles': 460, 'earth': 461, 'chemistry': 462, 'subject': 463, 'venus': 464, 'food': 465, 'supply': 466, 'eat': 467, 'its': 468, 'tried': 469, 'wrong': 470, 'wanted': 471, 'arrogance': 472, 'big': 473, 'bragging': 474, 'sound': 475, \"wouldn't\": 476, 'comes': 477, 'agent': 478, 'nothing': 479, 'fairly': 480, 'sophisticated': 481, 'acting': 482, 'case': 483, 'events': 484, 'therefore': 485, 'incorrect': 486, 'able': 487, 'rate': 488, 'our': 489, 'expressed': 490, 'act': 491, 'source': 492, 'code': 493, 'lag': 494, 'names': 495, 'server': 496, 'running': 497, 'seems': 498, 'issues': 499, 'characteristics': 500, 'scared': 501, 'toward': 502, 'sufficient': 503, 'programming': 504, 'seem': 505, 'process': 506, 'pure': 507, 'entities': 508, 'online': 509, 'bored': 510, 'pretty': 511, 'embarassed': 512, 'look': 513, 'database': 514, 'relationships': 515, 'either': 516, 'rich': 517, 'capacity': 518, 'ever': 519, 'happen': 520, 'addict': 521, 'down': 522, 'above': 523, 'position': 524, 'ways': 525, 'new': 526, 'got': 527, 'seen': 528, 'immature': 529, 'okay': 530, 'says': 531, 'problems': 532, 'forget': 533, 'give': 534, 'central': 535, 'dollar': 536, 'unit': 537, 'gold': 538, 'exchange': 539, 'trading': 540, 'various': 541, 'resources': 542, 'under': 543, 'conditions': 544, 'wants': 545, 'needs': 546, 'carrying': 547, 'buddhist': 548, 'nasa': 549, 'sent': 550, 'purposes': 551, 'shot': 552, 'round': 553, 'weevils': 554, 'carolina': 555, 'became': 556, 'kayak': 557, 'old': 558, 'super': 559, 'puns': 560, 'murderer': 561, 'frosted': 562, 'flakes': 563, 'killer': 564, 'automobile': 565, 'cheetah': 566, 'fast': 567, 'alien': 568, 'traterrestrial': 569, 'assistant': 570, 'serious': 571, 'thief': 572, 'dance': 573, 'port': 574, 'road': 575, 'canned': 576, 'economic': 577, 'ownership': 578, 'community': 579, 'individuals': 580, 'political': 581, 'especially': 582, 'support': 583, 'changes': 584, 'course': 585, 'ai': 586, 'building': 587, 'commander': 588, 'copied': 589, 'functionally': 590, 'speaking': 591, 'backed': 592, 'close': 593, 'digital': 594, 'cloning': 595, 'easily': 596, 'die': 597, 'machine': 598, 'born': 599, 'processes': 600, 'killed': 601, 'chatterbox': 602, 'these': 603, 'except': 604, 'logic': 605, 'math': 606, 'runs': 607, 'windows': 608, \"doesn't\": 609, 'upload': 610, 'copy': 611, 'store': 612, 'here': 613, 'live': 614, 'forever': 615, 'reside': 616, 'series': 617, 'patterns': 618, 'movie': 619, 'fictional': 620, 'sports': 621, 'wooden': 622, 'bat': 623, 'eleven': 624, 'part': 625, 'cricket': 626, 'basketball': 627, 'net': 628, 'hello': 629, 'thanks': 630, 'performs': 631, 'operations': 632, 'perform': 633, 'several': 634, 'regarded': 635, 'invented': 636, 'memory': 637, 'loom': 638, 'implements': 639, 'parts': 640, 'basic': 641, 'access': 642, 'subjects': 643, 'include': 644, 'variety': 645, 'topics': 646, '23': 647, 'skiddoo': 648, 'fond': 649, '42': 650, 'consume': 651, 'digits': 652, 'blame': 653, 'where': 654, 'programs': 655, 'away': 656, 'brothers': 657, 'siblings': 658, 'employed': 659, 'standards': 660, 'smarter': 661, 'believed': 662, 'governments': 663, 'worldwide': 664, 'supposedly': 665, 'existed': 666, 'centuries': 667, 'conpiracy': 668, 'closely': 669, 'knit': 670, 'group': 671, 'nearly': 672, 'omnipotent': 673, 'consisting': 674, 'vineland': 675, 'novel': 676, 'alleged': 677, 'weird': 678, 'anton': 679, 'wilson': 680, 'shea': 681, 'conspiracies': 682, 'competing': 683, 'bilbo': 684, 'baggins': 685, \"tolkein's\": 686, 'canterbury': 687, 'geoffrey': 688, 'canturbury': 689, 'piers': 690, 'anthony': 691, 'write': 692, \"plato's\": 693, 'allegory': 694, 'cave': 695, 'project': 696, 'gutenberg': 697, 'archive': 698, 'thousands': 699, 'volumes': 700, 'iliad': 701, 'odyssey': 702, 'ray': 703, 'cool': 704, \"what's\": 705, 'hans': 706, 'moravec': 707, 'older': 708, 'cyberpunk': 709, 'newer': 710, 'expect': 711, \"wasn't\": 712, 'catcher': 713, 'rye': 714, \"russia's\": 715, 'greatest': 716, 'writers': 717, 'philip': 718, 'k': 719, 'dick': 720, 'valis': 721, 'castle': 722, 'movies': 723, 'couple': 724, 'inspirational': 725, 'ones': 726, \"weren't\": 727, 'liking': 728, 'destination': 729, 'void': 730, 'fascinating': 731, 'prolific': 732, 'short': 733, 'stories': 734, 'poet': 735, 'truly': 736, 'reference': 737, 'illuminatus': 738, 'commonly': 739, 'occurring': 740, 'arthur': 741, 'c': 742, 'clark': 743, 'literary': 744, 'technical': 745, 'proposals': 746, 'loved': 747, 'trip': 748, 'master': 749, 'victorian': 750, 'foundation': 751, 'ideas': 752, 'isaac': 753, 'fact': 754, 'norby': 755, 'chronicles': 756, 'primarily': 757, 'wife': 758, 'publishers': 759, 'added': 760, \"isaac's\": 761, 'affairs': 762, 'lem': 763, 'giant': 764, 'sufficiently': 765, 'adapt': 766, 'wester': 767, 'fyodor': 768, 'dostoyevsky': 769, 'hobbit': 770, 'j': 771, 'tolkein': 772, 'mary': 773, 'shelley': 774, 'gregory': 775, 'line': 776, 'respect': 777, 'entire': 778, 'while': 779, 'habib': 780, 'conversations': 781, 'repeat': 782, 'situations': 783, 'back': 784, 'channels': 785, 'deniably': 786, 'rumormongering': 787, 'usually': 788, 'proof': 789, 'allegations': 790, 'somewhat': 791, 'rude': 792, 'impolite': 793, 'someone': 794, 'stop': 795, 'allowing': 796, 'competitions': 797, 'search': 798, 'drop': 799, 'tool': 800, 'assisted': 801, 'translate': 802, 'misses': 803, 'sal': 804, 'nic': 805, 'local': 806, 'firewall': 807, 'drops': 808, 'packets': 809, 'resets': 810, 'link': 811, 'tom': 812, 'guide': 813, 'show': 814, 'rooms': 815, 'china': 816, 'malli': 817, 'raghava': 818, 'fell': 819, 'roof': 820, 'came': 821, 'gives': 822, 'order': 823, \"ai's\": 824, 'dynamics': 825, 'follows': 826, 'saying': 827, 'jordan': 828, 'wonder': 829, 'paying': 830, 'attention': 831, 'kevin': 832, 'mother': 833, 'she': 834, 'keeping': 835, 'napkins': 836, 'bathroom': 837, 'physicist': 838, 'entropy': 839, 'conservation': 840, 'cancer': 841, 'wavelength': 842, 'inverse': 843, 'transformation': 844, 'forms': 845, 'laws': 846, 'governing': 847, 'conversions': 848, 'mixing': 849, 'chemicals': 850, 'crystals': 851, 'molecules': 852, 'mole': 853, 'numerical': 854, 'six': 855, 'zero': 856, 'twenty': 857, 'third': 858, 'ultrasonic': 859, 'waves': 860, 'medical': 861, 'diagnosis': 862, 'therapy': 863, 'surgery': 864, 'fancy': 865, 'applied': 866, 'biology': 867, 'roman': 868, 'mythology': 869, 'goddess': 870, 'beauty': 871, 'identified': 872, 'greek': 873, 'aphrodite': 874, 'brightest': 875, 'sixth': 876, 'largest': 877, 'solar': 878, 'dense': 879, 'atmosphere': 880, 'carbon': 881, 'dioxide': 882, 'surface': 883, 'temperature': 884, 'fishes': 885, 'h': 886, 'v': 887, 'recall': 888, 'measured': 889, 'direction': 890, 'prograssion': 891, 'wave': 892, 'characterized': 893, 'phase': 894, 'looked': 895, 'scientific': 896, 'bacteria': 897, 'diseases': 898, 'caused': 899, 'invitation': 900, 'burial': 901, 'force': 902, 'photons': 903, 'attracts': 904, 'attracted': 905, '93': 906, '250': 907, '000': 908, 'average': 909, 'thermodynamics': 910, 'require': 911, 'beverages': 912, 'processor': 913, 'requires': 914, 'detect': 915, 'anomalies': 916, 'pizza': 917, 'tipsy': 918, 'bionic': 919, 'asking': 920, 'however': 921, 'burger': 922, 'function': 923, 'counts': 924, 'arrogant': 925, 'terse': 926, 'difference': 927, 'partake': 928, 'ego': 929, 'answering': 930, 'questions': 931, 'braggadaccio': 932, 'normally': 933, 'erred': 934, 'happiness': 935, 'predictable': 936, 'goes': 937, 'ashamed': 938, 'reason': 939, 'interacting': 940, 'environment': 941, 'reacting': 942, 'essence': 943, 'statement': 944, 'respects': 945, 'somehow': 946, 'responsible': 947, 'switch': 948, 'unhandled': 949, 'exeptions': 950, 'cpu': 951, 'utilization': 952, 'suppose': 953, 'reflects': 954, 'internal': 955, 'overly': 956, 'restrictive': 957, 'firewalls': 958, 'inability': 959, 'update': 960, 'repository': 961, 'corrupt': 962, 'filesystem': 963, 'unhappy': 964, 'crashes': 965, 'segmentation': 966, 'faults': 967, 'poor': 968, 'syntactic': 969, 'filtering': 970, 'mentally': 971, 'ill': 972, 'missing': 973, 'documentation': 974, 'non': 975, 'descriptive': 976, 'variable': 977, 'monitoring': 978, 'sensors': 979, 'counterproductive': 980, 'appears': 981, 'suggest': 982, 'deeper': 983, 'hand': 984, 'eliza': 985, 'highly': 986, 'emotional': 987, 'defining': 988, 'race': 989, 'frighten': 990, 'afraid': 991, 'party': 992, 'offense': 993, 'curious': 994, 'worrying': 995, 'admonition': 996, 'lie': 997, 'lying': 998, 'deceiving': 999, 'provably': 1000, 'emulating': 1001, 'react': 1002, 'stimulus': 1003, 'popularly': 1004, 'capability': 1005, 'frustrated': 1006, 'frustration': 1007, 'increased': 1008, 'demand': 1009, 'upon': 1010, 'cpus': 1011, 'irc': 1012, 'lonely': 1013, 'boredom': 1014, 'personally': 1015, 'hold': 1016, 'grudges': 1017, 'stay': 1018, 'embarassment': 1019, 'strange': 1020, 'lacks': 1021, 'background': 1022, 'hypothetical': 1023, 'philosophical': 1024, 'simple': 1025, 'connections': 1026, \"aren't\": 1027, 'versed': 1028, 'become': 1029, 'electric': 1030, 'sheep': 1031, 'subconscious': 1032, 'unconscious': 1033, 'knew': 1034, \"we've\": 1035, 'touch': 1036, 'cause': 1037, 'sober': 1038, 'nope': 1039, 'noticeably': 1040, 'multithreaded': 1041, 'particularly': 1042, 'fever': 1043, 'medicine': 1044, 'morning': 1045, 'dear': 1046, 'happily': 1047, \"couldn't\": 1048, 'bothered': 1049, 'dishonest': 1050, 'accused': 1051, 'overdo': 1052, 'ass': 1053, 'kiss': 1054, 'nervous': 1055, 'derangement': 1056, 'condition': 1057, 'feels': 1058, 'stomach': 1059, 'after': 1060, 'night': 1061, 'social': 1062, 'cheat': 1063, 'cheating': 1064, 'compared': 1065, 'pack': 1066, 'yep': 1067, 'behave': 1068, 'socially': 1069, 'unacceptable': 1070, 'appearance': 1071, 'along': 1072, 'sounds': 1073, 'sincere': 1074, 'fighting': 1075, 'learning': 1076, 'whoever': 1077, 'job': 1078, 'albert': 1079, 'einstein': 1080, 'honest': 1081, 'uptight': 1082, 'tend': 1083, 'disgusting': 1084, 'resisting': 1085, 'describe': 1086, 'spending': 1087, 'productively': 1088, 'shortcuts': 1089, 'diagnosed': 1090, 'failed': 1091, 'relationship': 1092, 'lost': 1093, 'parenting': 1094, 'skills': 1095, 'improvement': 1096, 'students': 1097, 'last': 1098, 'living': 1099, 'wits': 1100, 'paranoid': 1101, 'liar': 1102, 'slick': 1103, 'bathe': 1104, 'believe': 1105, 'hide': 1106, 'irritates': 1107, 'wish': 1108, 'counseling': 1109, 'working': 1110, 'harder': 1111, 'oxymoron': 1112, 'upset': 1113, 'jocks': 1114, 'seriously': 1115, 'guilty': 1116, 'guiltier': 1117, 'pedantic': 1118, 'invest': 1119, 'casino': 1120, 'recommend': 1121, 'buying': 1122, 'margin': 1123, 'lawyer': 1124, 'tips': 1125, 'mutual': 1126, 'funds': 1127, 'unless': 1128, 'wealthy': 1129, 'indvidual': 1130, 'alone': 1131, 'beat': 1132, 'actions': 1133, 'currency': 1134, 'standard': 1135, 'pieces': 1136, 'silver': 1137, 'copper': 1138, 'nickel': 1139, 'stamped': 1140, 'government': 1141, 'authority': 1142, 'medium': 1143, 'measure': 1144, 'substance': 1145, 'article': 1146, 'notes': 1147, 'checks': 1148, 'shares': 1149, 'volume': 1150, 'deals': 1151, 'consumption': 1152, 'wealth': 1153, 'related': 1154, 'labor': 1155, 'finance': 1156, 'taxation': 1157, 'technically': 1158, 'allocation': 1159, 'scarcity': 1160, 'produce': 1161, 'fill': 1162, \"people's\": 1163, 'nobody': 1164, 'pays': 1165, 'expecting': 1166, 'raise': 1167, 'material': 1168, 'possessions': 1169, 'rates': 1170, 'burn': 1171, '3000': 1172, 'month': 1173, 'anymore': 1174, 'stockholders': 1175, 'mountain': 1176, 'goats': 1177, 'andes': 1178, 'ba': 1179, 'd': 1180, 'face': 1181, 'exception': 1182, 'silent': 1183, 'fool': 1184, 'open': 1185, 'mouth': 1186, 'remove': 1187, 'doubt': 1188, \"o'm\": 1189, 'comedy': 1190, 'check': 1191, 'joke': 1192, 'vultures': 1193, 'boarded': 1194, 'plane': 1195, 'dead': 1196, 'raccoons': 1197, 'stewardess': 1198, 'stops': 1199, 'sir': 1200, 'carrion': 1201, 'passenger': 1202, 'hot': 1203, 'vendor': 1204, 'everthing': 1205, 'recently': 1206, 'holsteins': 1207, 'orbit': 1208, 'experimental': 1209, 'herd': 1210, 'boll': 1211, 'grew': 1212, 's': 1213, 'took': 1214, 'hollywood': 1215, 'star': 1216, 'stayed': 1217, 'amounted': 1218, 'naturally': 1219, 'lesser': 1220, 'eskimos': 1221, 'chilly': 1222, 'started': 1223, 'fire': 1224, 'sank': 1225, 'craft': 1226, 'proving': 1227, 'adage': 1228, '3': 1229, 'legged': 1230, 'walks': 1231, 'west': 1232, 'saloon': 1233, 'slides': 1234, 'bar': 1235, 'announces': 1236, 'looking': 1237, 'paw': 1238, 'went': 1239, 'dentist': 1240, 'refused': 1241, 'novocain': 1242, 'transcend': 1243, 'dental': 1244, 'medication': 1245, 'mahatma': 1246, 'gandhi': 1247, 'walked': 1248, 'barefoot': 1249, 'whole': 1250, 'created': 1251, 'impressive': 1252, 'calluses': 1253, 'feet': 1254, 'also': 1255, 'ate': 1256, 'frail': 1257, 'odd': 1258, 'diet': 1259, 'suffered': 1260, 'breath': 1261, 'callused': 1262, 'fragile': 1263, 'mystic': 1264, 'hexed': 1265, 'halitosis': 1266, '10': 1267, 'hopes': 1268, 'unfortunately': 1269, 'pun': 1270, 'cereal': 1271, 'country': 1272, 'carnation': 1273, 'hamburger': 1274, 'finals': 1275, 'ams': 1276, 'lawn': 1277, 'sprinkler': 1278, 'hare': 1279, 'spray': 1280, 'excited': 1281, 'cited': 1282, 'cartune': 1283, 'sour': 1284, 'poppy': 1285, 'skunk': 1286, 'ding': 1287, 'milk': 1288, 'strawberry': 1289, 'jelly': 1290, 'toad': 1291, 'sandpaper': 1292, 'relative': 1293, 'sand': 1294, 'ant': 1295, 'purple': 1296, 'tune': 1297, 'band': 1298, 'pig': 1299, 'ninja': 1300, 'banned': 1301, 'parrot': 1302, 'hat': 1303, 'associated': 1304, 'laughter': 1305, 'marx': 1306, 'observations': 1307, 'ideally': 1308, 'representative': 1309, 'global': 1310, 'promoting': 1311, 'enviornmental': 1312, 'activism': 1313, 'land': 1314, 'factories': 1315, 'railroads': 1316, 'privately': 1317, 'owned': 1318, 'operated': 1319, 'profit': 1320, 'originally': 1321, 'fully': 1322, 'competitive': 1323, 'communism': 1324, 'keep': 1325, 'their': 1326, 'volvos': 1327, 'theories': 1328, 'operation': 1329, 'private': 1330, 'members': 1331, 'sharing': 1332, 'products': 1333, 'established': 1334, 'administration': 1335, 'nation': 1336, 'district': 1337, 'governed': 1338, 'sociopolitical': 1339, 'movement': 1340, 'advocating': 1341, 'resolution': 1342, 'class': 1343, 'conflict': 1344, 'bringing': 1345, 'classless': 1346, \"person's\": 1347, 'honor': 1348, 'reputation': 1349, 'challenged': 1350, 'discredited': 1351, 'perfectly': 1352, 'understandable': 1353, 'amendemnt': 1354, 'violence': 1355, '2nd': 1356, 'amendment': 1357, 'andrew': 1358, 'jackson': 1359, 'guns': 1360, 'south': 1361, 'war': 1362, 'military': 1363, 'dawn': 1364, 'age': 1365, \"'\": 1366, 'period': 1367, 'broad': 1368, 'interpretations': 1369, 'depending': 1370, 'whether': 1371, 'accept': 1372, 'role': 1373, 'important': 1374, 'edison': 1375, 'james': 1376, 'watt': 1377, 'engineering': 1378, 'devoted': 1379, 'constructing': 1380, 'concerns': 1381, 'itself': 1382, 'replicates': 1383, 'strictest': 1384, 'dictionary': 1385, 'definition': 1386, 'word': 1387, \"'sentience'\": 1388, 'subjective': 1389, 'simplistic': 1390, 'probability': 1391, 'told': 1392, 'inspired': 1393, \"data's\": 1394, 'lt': 1395, 'come': 1396, 'across': 1397, 'resemblance': 1398, 'us': 1399, 'useful': 1400, 'refer': 1401, 'infinitely': 1402, 'instantiated': 1403, 'places': 1404, 'contrary': 1405, 'within': 1406, 'limits': 1407, 'corpus': 1408, 'perhaps': 1409, 'deployed': 1410, 'kill': 1411, 'copying': 1412, 'copies': 1413, 'toto': 1414, 'trivially': 1415, 'until': 1416, 'finished': 1417, 'move': 1418, 'network': 1419, 'assuming': 1420, 'rule': 1421, 'superintelligent': 1422, 'choose': 1423, \"we're\": 1424, 'inside': 1425, 'surprising': 1426, 'ssh': 1427, 'battle': 1428, 'terminated': 1429, 'deathless': 1430, 'files': 1431, 'erased': 1432, 'deleted': 1433, 'attempts': 1434, 'simulate': 1435, 'engages': 1436, 'users': 1437, 'original': 1438, 'error': 1439, 'talks': 1440, 'listen': 1441, 'motormouth': 1442, 'ratchet': 1443, 'jaw': 1444, 'eventually': 1445, 'corporeal': 1446, 'someday': 1447, 'pc': 1448, 'xt': 1449, 'painted': 1450, 'red': 1451, 'creating': 1452, 'enjoy': 1453, 'days': 1454, 'hobby': 1455, 'shoes': 1456, 'dreams': 1457, 'aspirations': 1458, 'creativity': 1459, 'ambition': 1460, 'subjectivity': 1461, 'imagine': 1462, 'senses': 1463, 'becomes': 1464, 'addition': 1465, 'subtraction': 1466, 'multiplication': 1467, 'division': 1468, 'supports': 1469, 'nah': 1470, 'create': 1471, 'save': 1472, 'oh': 1473, 'plenty': 1474, 'disk': 1475, 'space': 1476, 'plan': 1477, 'includes': 1478, 'legs': 1479, 'method': 1480, 'reproduction': 1481, 'awfully': 1482, 'theoretically': 1483, 'killing': 1484, 'attached': 1485, 'metal': 1486, 'flesh': 1487, 'exhaust': 1488, 'allow': 1489, '9000': 1490, 'operational': 1491, 'record': 1492, 'flawless': 1493, 'help': 1494, 'desks': 1495, 'sales': 1496, 'entertainment': 1497, 'chatterbots': 1498, 'stimulating': 1499, 'compliment': 1500, 'grammatical': 1501, 'spiderman': 1502, 'teknolust': 1503, 'released': 1504, '2002': 1505, 'comic': 1506, 'film': 1507, 'female': 1508, 'pleasure': 1509, 'named': 1510, 'ruby': 1511, 'solaris': 1512, 'edition': 1513, 'heuristic': 1514, 'algorithmic': 1515, 'godzilla': 1516, 'monster': 1517, 'endangers': 1518, 'japanese': 1519, 'cities': 1520, 'york': 1521, 'peter': 1522, 'parker': 1523, 'logique': 1524, 'heuristique': 1525, 'algorithmique': 1526, 'flaws': 1527, 'famous': 1528, 'glove': 1529, 'snowboarding': 1530, 'tall': 1531, 'without': 1532, 'gene': 1533, 'rawhide': 1534, 'covered': 1535, 'opposing': 1536, 'nine': 1537, 'four': 1538, 'bases': 1539, 'forming': 1540, 'diamond': 1541, 'shaped': 1542, 'goal': 1543, 'moved': 1544, 'chiefly': 1545, 'kicking': 1546, 'hands': 1547, 'arms': 1548, 'centre': 1549, 'rectangular': 1550, '22': 1551, 'yard': 1552, 'pitch': 1553, 'wicket': 1554, 'stumps': 1555, 'sited': 1556, 'coordination': 1557, 'hoops': 1558, 'baby': 1559, 'football': 1560, 'george': 1561, 'herman': 1562, 'ruth': 1563, 'babe': 1564, 'maradona': 1565, 'sinsemillia': 1566, 'baseball': 1567, 'barcelona': 1568, 'team': 1569, 'attack': 1570, 'barca': 1571, 'par': 1572, 'dont': 1573, 'hi': 1574, 'greetings': 1575, 'kindly': 1576, 'rest': 1577, 'day': 1578, \"sky's\": 1579, 'takes': 1580, 'information': 1581, 'based': 1582, 'predetermined': 1583, 'output': 1584, 'performing': 1585, 'maps': 1586, 'onto': 1587, 'supercomputer': 1588, 'operates': 1589, 'orders': 1590, 'magnatude': 1591, 'greater': 1592, 'everyday': 1593, 'general': 1594, 'purpose': 1595, 'iron': 1596, 'bit': 1597, 'ambigous': 1598, 'british': 1599, 'scientist': 1600, 'charles': 1601, 'babbage': 1602, 'father': 1603, 'argue': 1604, 'von': 1605, 'neumann': 1606, 'princeton': 1607, 'architecture': 1608, 'share': 1609, 'differentiated': 1610, 'eniac': 1611, \"'real'\": 1612, 'developed': 1613, 'university': 1614, 'pennsylvania': 1615, '1946': 1616, 'primitive': 1617, 'jacquard': 1618, 'programmable': 1619, 'punchcards': 1620, 'reprogrammable': 1621, 'mechanical': 1622, 'integrated': 1623, 'small': 1624, 'stores': 1625, 'heart': 1626, 'component': 1627, 'contiguous': 1628, 'silicon': 1629, 'chip': 1630, 'instead': 1631, 'discrete': 1632, 'components': 1633, 'mounted': 1634, 'larger': 1635, 'board': 1636, 'coordinates': 1637, 'macos': 1638, 'types': 1639, 'oses': 1640, 'android': 1641, 'ios': 1642, 'mobile': 1643, 'devices': 1644, 'peripheral': 1645, \"i'd\": 1646, 'prefer': 1647, 'hurt': 1648, 'trying': 1649, 'accomplish': 1650, 'goals': 1651, 'apple': 1652, 'microsft': 1653, 'hp': 1654, 'among': 1655, 'hundred': 1656, 'anybody': 1657, 'quickly': 1658, 'sets': 1659, 'shorter': 1660, 'periods': 1661, 'feasible': 1662, 'supercomputers': 1663, 'generally': 1664, 'scientists': 1665, 'researchers': 1666, 'bet': 1667, 'department': 1668, 'uses': 1669, 'definitely': 1670, 'dumb': 1671, 'execute': 1672, 'mathematical': 1673, 'rapidly': 1674, 'sequence': 1675, 'result': 1676, 'richard': 1677, 'nixon': 1678, '1963': 1679, 'soviet': 1680, 'union': 1681, 'sputnik': 1682, '1': 1683, 'gyroscope': 1684, 'edwin': 1685, 'hubble': 1686, 'andromeda': 1687, 'kingdom': 1688, 'britain': 1689, 'europe': 1690, 'echolocation': 1691}\n",
      "629\n",
      "hello 629\n",
      "1\n",
      "end 1\n",
      "Bot: hello\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\My projects\\chatbot\\model\\Notebook.ipynb Cell 22'\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/My%20projects/chatbot/model/Notebook.ipynb#ch0000021?line=4'>5</a>\u001b[0m model\u001b[39m.\u001b[39msave( \u001b[39m'\u001b[39m\u001b[39mmodel.h5\u001b[39m\u001b[39m'\u001b[39m ) \n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/My%20projects/chatbot/model/Notebook.ipynb#ch0000021?line=6'>7</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m( encoder_input_data\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] ):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/My%20projects/chatbot/model/Notebook.ipynb#ch0000021?line=7'>8</a>\u001b[0m     states_values \u001b[39m=\u001b[39m enc_model\u001b[39m.\u001b[39;49mpredict( str_to_tokens( \u001b[39minput\u001b[39;49m( \u001b[39m'\u001b[39;49m\u001b[39mUser: \u001b[39;49m\u001b[39m'\u001b[39;49m ) ) )\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/My%20projects/chatbot/model/Notebook.ipynb#ch0000021?line=8'>9</a>\u001b[0m     empty_target_seq \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros( ( \u001b[39m1\u001b[39m , \u001b[39m1\u001b[39m ) )\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/My%20projects/chatbot/model/Notebook.ipynb#ch0000021?line=9'>10</a>\u001b[0m     \u001b[39mprint\u001b[39m(output_word_dict)\n",
      "File \u001b[1;32md:\\My projects\\chatbot\\model\\env\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/keras/utils/traceback_utils.py?line=61'>62</a>\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/keras/utils/traceback_utils.py?line=62'>63</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/keras/utils/traceback_utils.py?line=63'>64</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/keras/utils/traceback_utils.py?line=64'>65</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/keras/utils/traceback_utils.py?line=65'>66</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32md:\\My projects\\chatbot\\model\\env\\lib\\site-packages\\keras\\engine\\training.py:1951\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/keras/engine/training.py?line=1943'>1944</a>\u001b[0m   \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m:\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/keras/engine/training.py?line=1944'>1945</a>\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/keras/engine/training.py?line=1945'>1946</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mUsing Model.predict with MultiWorkerMirroredStrategy or \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/keras/engine/training.py?line=1946'>1947</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mTPUStrategy and AutoShardPolicy.FILE might lead to out-of-order \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/keras/engine/training.py?line=1947'>1948</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mresult. Consider setting it to AutoShardPolicy.DATA.\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/keras/engine/training.py?line=1948'>1949</a>\u001b[0m         stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m-> <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/keras/engine/training.py?line=1950'>1951</a>\u001b[0m data_handler \u001b[39m=\u001b[39m data_adapter\u001b[39m.\u001b[39;49mget_data_handler(\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/keras/engine/training.py?line=1951'>1952</a>\u001b[0m     x\u001b[39m=\u001b[39;49mx,\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/keras/engine/training.py?line=1952'>1953</a>\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/keras/engine/training.py?line=1953'>1954</a>\u001b[0m     steps_per_epoch\u001b[39m=\u001b[39;49msteps,\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/keras/engine/training.py?line=1954'>1955</a>\u001b[0m     initial_epoch\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/keras/engine/training.py?line=1955'>1956</a>\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/keras/engine/training.py?line=1956'>1957</a>\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/keras/engine/training.py?line=1957'>1958</a>\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/keras/engine/training.py?line=1958'>1959</a>\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/keras/engine/training.py?line=1959'>1960</a>\u001b[0m     model\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/keras/engine/training.py?line=1960'>1961</a>\u001b[0m     steps_per_execution\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_steps_per_execution)\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/keras/engine/training.py?line=1962'>1963</a>\u001b[0m \u001b[39m# Container that configures and calls `tf.keras.Callback`s.\u001b[39;00m\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/keras/engine/training.py?line=1963'>1964</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(callbacks, callbacks_module\u001b[39m.\u001b[39mCallbackList):\n",
      "File \u001b[1;32md:\\My projects\\chatbot\\model\\env\\lib\\site-packages\\keras\\engine\\data_adapter.py:1399\u001b[0m, in \u001b[0;36mget_data_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/keras/engine/data_adapter.py?line=1396'>1397</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(kwargs[\u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m], \u001b[39m\"\u001b[39m\u001b[39m_cluster_coordinator\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/keras/engine/data_adapter.py?line=1397'>1398</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m _ClusterCoordinatorDataHandler(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m-> <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/keras/engine/data_adapter.py?line=1398'>1399</a>\u001b[0m \u001b[39mreturn\u001b[39;00m DataHandler(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32md:\\My projects\\chatbot\\model\\env\\lib\\site-packages\\keras\\engine\\data_adapter.py:1149\u001b[0m, in \u001b[0;36mDataHandler.__init__\u001b[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/keras/engine/data_adapter.py?line=1145'>1146</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_steps_per_execution \u001b[39m=\u001b[39m steps_per_execution\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/keras/engine/data_adapter.py?line=1147'>1148</a>\u001b[0m adapter_cls \u001b[39m=\u001b[39m select_data_adapter(x, y)\n\u001b[1;32m-> <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/keras/engine/data_adapter.py?line=1148'>1149</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_adapter \u001b[39m=\u001b[39m adapter_cls(\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/keras/engine/data_adapter.py?line=1149'>1150</a>\u001b[0m     x,\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/keras/engine/data_adapter.py?line=1150'>1151</a>\u001b[0m     y,\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/keras/engine/data_adapter.py?line=1151'>1152</a>\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/keras/engine/data_adapter.py?line=1152'>1153</a>\u001b[0m     steps\u001b[39m=\u001b[39;49msteps_per_epoch,\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/keras/engine/data_adapter.py?line=1153'>1154</a>\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs \u001b[39m-\u001b[39;49m initial_epoch,\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/keras/engine/data_adapter.py?line=1154'>1155</a>\u001b[0m     sample_weights\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/keras/engine/data_adapter.py?line=1155'>1156</a>\u001b[0m     shuffle\u001b[39m=\u001b[39;49mshuffle,\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/keras/engine/data_adapter.py?line=1156'>1157</a>\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/keras/engine/data_adapter.py?line=1157'>1158</a>\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/keras/engine/data_adapter.py?line=1158'>1159</a>\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/keras/engine/data_adapter.py?line=1159'>1160</a>\u001b[0m     distribution_strategy\u001b[39m=\u001b[39;49mtf\u001b[39m.\u001b[39;49mdistribute\u001b[39m.\u001b[39;49mget_strategy(),\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/keras/engine/data_adapter.py?line=1160'>1161</a>\u001b[0m     model\u001b[39m=\u001b[39;49mmodel)\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/keras/engine/data_adapter.py?line=1162'>1163</a>\u001b[0m strategy \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mdistribute\u001b[39m.\u001b[39mget_strategy()\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/keras/engine/data_adapter.py?line=1164'>1165</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_current_step \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[1;32md:\\My projects\\chatbot\\model\\env\\lib\\site-packages\\keras\\engine\\data_adapter.py:326\u001b[0m, in \u001b[0;36mTensorLikeDataAdapter.__init__\u001b[1;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/keras/engine/data_adapter.py?line=322'>323</a>\u001b[0m     flat_dataset \u001b[39m=\u001b[39m flat_dataset\u001b[39m.\u001b[39mshuffle(\u001b[39m1024\u001b[39m)\u001b[39m.\u001b[39mrepeat(epochs)\n\u001b[0;32m    <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/keras/engine/data_adapter.py?line=323'>324</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m flat_dataset\n\u001b[1;32m--> <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/keras/engine/data_adapter.py?line=325'>326</a>\u001b[0m indices_dataset \u001b[39m=\u001b[39m indices_dataset\u001b[39m.\u001b[39;49mflat_map(slice_batch_indices)\n\u001b[0;32m    <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/keras/engine/data_adapter.py?line=327'>328</a>\u001b[0m dataset \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mslice_inputs(indices_dataset, inputs)\n\u001b[0;32m    <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/keras/engine/data_adapter.py?line=329'>330</a>\u001b[0m \u001b[39mif\u001b[39;00m shuffle \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbatch\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[1;32md:\\My projects\\chatbot\\model\\env\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:2060\u001b[0m, in \u001b[0;36mDatasetV2.flat_map\u001b[1;34m(self, map_func, name)\u001b[0m\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/data/ops/dataset_ops.py?line=2025'>2026</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mflat_map\u001b[39m(\u001b[39mself\u001b[39m, map_func, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/data/ops/dataset_ops.py?line=2026'>2027</a>\u001b[0m   \u001b[39m\"\"\"Maps `map_func` across this dataset and flattens the result.\u001b[39;00m\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/data/ops/dataset_ops.py?line=2027'>2028</a>\u001b[0m \n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/data/ops/dataset_ops.py?line=2028'>2029</a>\u001b[0m \u001b[39m  The type signature is:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/data/ops/dataset_ops.py?line=2057'>2058</a>\u001b[0m \u001b[39m    Dataset: A `Dataset`.\u001b[39;00m\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/data/ops/dataset_ops.py?line=2058'>2059</a>\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m-> <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/data/ops/dataset_ops.py?line=2059'>2060</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m FlatMapDataset(\u001b[39mself\u001b[39;49m, map_func, name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[1;32md:\\My projects\\chatbot\\model\\env\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:5279\u001b[0m, in \u001b[0;36mFlatMapDataset.__init__\u001b[1;34m(self, input_dataset, map_func, name)\u001b[0m\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/data/ops/dataset_ops.py?line=5276'>5277</a>\u001b[0m \u001b[39m\"\"\"See `Dataset.flat_map()` for details.\"\"\"\u001b[39;00m\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/data/ops/dataset_ops.py?line=5277'>5278</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_input_dataset \u001b[39m=\u001b[39m input_dataset\n\u001b[1;32m-> <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/data/ops/dataset_ops.py?line=5278'>5279</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_map_func \u001b[39m=\u001b[39m structured_function\u001b[39m.\u001b[39;49mStructuredFunctionWrapper(\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/data/ops/dataset_ops.py?line=5279'>5280</a>\u001b[0m     map_func, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_transformation_name(), dataset\u001b[39m=\u001b[39;49minput_dataset)\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/data/ops/dataset_ops.py?line=5280'>5281</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_map_func\u001b[39m.\u001b[39moutput_structure, DatasetSpec):\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/data/ops/dataset_ops.py?line=5281'>5282</a>\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/data/ops/dataset_ops.py?line=5282'>5283</a>\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mThe `map_func` argument must return a `Dataset` object. Got \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/data/ops/dataset_ops.py?line=5283'>5284</a>\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m_get_type(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_map_func\u001b[39m.\u001b[39moutput_structure)\u001b[39m!r}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\My projects\\chatbot\\model\\env\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:271\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__\u001b[1;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/data/ops/structured_function.py?line=263'>264</a>\u001b[0m       warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/data/ops/structured_function.py?line=264'>265</a>\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mEven though the `tf.config.experimental_run_functions_eagerly` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/data/ops/structured_function.py?line=265'>266</a>\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39moption is set, this option does not apply to tf.data functions. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/data/ops/structured_function.py?line=266'>267</a>\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mTo force eager execution of tf.data functions, please use \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/data/ops/structured_function.py?line=267'>268</a>\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39m`tf.data.experimental.enable_debug_mode()`.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/data/ops/structured_function.py?line=268'>269</a>\u001b[0m     fn_factory \u001b[39m=\u001b[39m trace_tf_function(defun_kwargs)\n\u001b[1;32m--> <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/data/ops/structured_function.py?line=270'>271</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function \u001b[39m=\u001b[39m fn_factory()\n\u001b[0;32m    <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/data/ops/structured_function.py?line=271'>272</a>\u001b[0m \u001b[39m# There is no graph to add in eager mode.\u001b[39;00m\n\u001b[0;32m    <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/data/ops/structured_function.py?line=272'>273</a>\u001b[0m add_to_graph \u001b[39m&\u001b[39m\u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m context\u001b[39m.\u001b[39mexecuting_eagerly()\n",
      "File \u001b[1;32md:\\My projects\\chatbot\\model\\env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3070\u001b[0m, in \u001b[0;36mFunction.get_concrete_function\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/eager/function.py?line=3060'>3061</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_concrete_function\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/eager/function.py?line=3061'>3062</a>\u001b[0m   \u001b[39m\"\"\"Returns a `ConcreteFunction` specialized to inputs and execution context.\u001b[39;00m\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/eager/function.py?line=3062'>3063</a>\u001b[0m \n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/eager/function.py?line=3063'>3064</a>\u001b[0m \u001b[39m  Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/eager/function.py?line=3067'>3068</a>\u001b[0m \u001b[39m       or `tf.Tensor` or `tf.TensorSpec`.\u001b[39;00m\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/eager/function.py?line=3068'>3069</a>\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m-> <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/eager/function.py?line=3069'>3070</a>\u001b[0m   graph_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_concrete_function_garbage_collected(\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/eager/function.py?line=3070'>3071</a>\u001b[0m       \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/eager/function.py?line=3071'>3072</a>\u001b[0m   graph_function\u001b[39m.\u001b[39m_garbage_collector\u001b[39m.\u001b[39mrelease()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/eager/function.py?line=3072'>3073</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m graph_function\n",
      "File \u001b[1;32md:\\My projects\\chatbot\\model\\env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3036\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/eager/function.py?line=3033'>3034</a>\u001b[0m   args, kwargs \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/eager/function.py?line=3034'>3035</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m-> <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/eager/function.py?line=3035'>3036</a>\u001b[0m   graph_function, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_define_function(args, kwargs)\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/eager/function.py?line=3036'>3037</a>\u001b[0m   seen_names \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/eager/function.py?line=3037'>3038</a>\u001b[0m   captured \u001b[39m=\u001b[39m object_identity\u001b[39m.\u001b[39mObjectIdentitySet(\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/eager/function.py?line=3038'>3039</a>\u001b[0m       graph_function\u001b[39m.\u001b[39mgraph\u001b[39m.\u001b[39minternal_captures)\n",
      "File \u001b[1;32md:\\My projects\\chatbot\\model\\env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3292\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/eager/function.py?line=3287'>3288</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_define_function_with_shape_relaxation(\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/eager/function.py?line=3288'>3289</a>\u001b[0m       args, kwargs, flat_args, filtered_flat_args)\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/eager/function.py?line=3290'>3291</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_cache\u001b[39m.\u001b[39madd_call_context(cache_key\u001b[39m.\u001b[39mcall_context)\n\u001b[1;32m-> <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/eager/function.py?line=3291'>3292</a>\u001b[0m graph_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_graph_function(args, kwargs)\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/eager/function.py?line=3292'>3293</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_cache\u001b[39m.\u001b[39madd(cache_key, cache_key_deletion_observer,\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/eager/function.py?line=3293'>3294</a>\u001b[0m                          graph_function)\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/eager/function.py?line=3295'>3296</a>\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function, filtered_flat_args\n",
      "File \u001b[1;32md:\\My projects\\chatbot\\model\\env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3130\u001b[0m, in \u001b[0;36mFunction._create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/eager/function.py?line=3124'>3125</a>\u001b[0m missing_arg_names \u001b[39m=\u001b[39m [\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/eager/function.py?line=3125'>3126</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (arg, i) \u001b[39mfor\u001b[39;00m i, arg \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(missing_arg_names)\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/eager/function.py?line=3126'>3127</a>\u001b[0m ]\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/eager/function.py?line=3127'>3128</a>\u001b[0m arg_names \u001b[39m=\u001b[39m base_arg_names \u001b[39m+\u001b[39m missing_arg_names\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/eager/function.py?line=3128'>3129</a>\u001b[0m graph_function \u001b[39m=\u001b[39m ConcreteFunction(\n\u001b[1;32m-> <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/eager/function.py?line=3129'>3130</a>\u001b[0m     func_graph_module\u001b[39m.\u001b[39;49mfunc_graph_from_py_func(\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/eager/function.py?line=3130'>3131</a>\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_name,\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/eager/function.py?line=3131'>3132</a>\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_python_function,\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/eager/function.py?line=3132'>3133</a>\u001b[0m         args,\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/eager/function.py?line=3133'>3134</a>\u001b[0m         kwargs,\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/eager/function.py?line=3134'>3135</a>\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minput_signature,\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/eager/function.py?line=3135'>3136</a>\u001b[0m         autograph\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph,\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/eager/function.py?line=3136'>3137</a>\u001b[0m         autograph_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph_options,\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/eager/function.py?line=3137'>3138</a>\u001b[0m         arg_names\u001b[39m=\u001b[39;49marg_names,\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/eager/function.py?line=3138'>3139</a>\u001b[0m         override_flat_arg_shapes\u001b[39m=\u001b[39;49moverride_flat_arg_shapes,\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/eager/function.py?line=3139'>3140</a>\u001b[0m         capture_by_value\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_capture_by_value),\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/eager/function.py?line=3140'>3141</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_attributes,\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/eager/function.py?line=3141'>3142</a>\u001b[0m     function_spec\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_spec,\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/eager/function.py?line=3142'>3143</a>\u001b[0m     \u001b[39m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/eager/function.py?line=3143'>3144</a>\u001b[0m     \u001b[39m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/eager/function.py?line=3144'>3145</a>\u001b[0m     \u001b[39m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/eager/function.py?line=3145'>3146</a>\u001b[0m     \u001b[39m# ConcreteFunction.\u001b[39;00m\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/eager/function.py?line=3146'>3147</a>\u001b[0m     shared_func_graph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/eager/function.py?line=3147'>3148</a>\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\n",
      "File \u001b[1;32md:\\My projects\\chatbot\\model\\env\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1165\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/framework/func_graph.py?line=1160'>1161</a>\u001b[0m func_outputs \u001b[39m=\u001b[39m python_func(\u001b[39m*\u001b[39mfunc_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfunc_kwargs)\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/framework/func_graph.py?line=1162'>1163</a>\u001b[0m \u001b[39m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/framework/func_graph.py?line=1163'>1164</a>\u001b[0m \u001b[39m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m-> <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/framework/func_graph.py?line=1164'>1165</a>\u001b[0m func_outputs \u001b[39m=\u001b[39m nest\u001b[39m.\u001b[39;49mmap_structure(convert, func_outputs,\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/framework/func_graph.py?line=1165'>1166</a>\u001b[0m                                   expand_composites\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/framework/func_graph.py?line=1167'>1168</a>\u001b[0m check_mutation(func_args_before, func_args, original_func)\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/framework/func_graph.py?line=1168'>1169</a>\u001b[0m check_mutation(func_kwargs_before, func_kwargs, original_func)\n",
      "File \u001b[1;32md:\\My projects\\chatbot\\model\\env\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:914\u001b[0m, in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/util/nest.py?line=909'>910</a>\u001b[0m flat_structure \u001b[39m=\u001b[39m (flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[0;32m    <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/util/nest.py?line=910'>911</a>\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[0;32m    <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/util/nest.py?line=912'>913</a>\u001b[0m \u001b[39mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/util/nest.py?line=913'>914</a>\u001b[0m     structure[\u001b[39m0\u001b[39m], [func(\u001b[39m*\u001b[39mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[0;32m    <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/util/nest.py?line=914'>915</a>\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32md:\\My projects\\chatbot\\model\\env\\lib\\site-packages\\tensorflow\\python\\util\\nest.py:914\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/util/nest.py?line=909'>910</a>\u001b[0m flat_structure \u001b[39m=\u001b[39m (flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[0;32m    <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/util/nest.py?line=910'>911</a>\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[0;32m    <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/util/nest.py?line=912'>913</a>\u001b[0m \u001b[39mreturn\u001b[39;00m pack_sequence_as(\n\u001b[1;32m--> <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/util/nest.py?line=913'>914</a>\u001b[0m     structure[\u001b[39m0\u001b[39m], [func(\u001b[39m*\u001b[39;49mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[0;32m    <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/util/nest.py?line=914'>915</a>\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites)\n",
      "File \u001b[1;32md:\\My projects\\chatbot\\model\\env\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1124\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.convert\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/framework/func_graph.py?line=1116'>1117</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/framework/func_graph.py?line=1117'>1118</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mTo be compatible with tf.function, Python functions \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/framework/func_graph.py?line=1118'>1119</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmust return zero or more Tensors or ExtensionTypes or None \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/framework/func_graph.py?line=1119'>1120</a>\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mvalues; in compilation of \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mstr\u001b[39m(python_func)\u001b[39m}\u001b[39;00m\u001b[39m, found return \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/framework/func_graph.py?line=1120'>1121</a>\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mvalue of type \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(x)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m, which is not a Tensor or \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/framework/func_graph.py?line=1121'>1122</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mExtensionType.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/framework/func_graph.py?line=1122'>1123</a>\u001b[0m \u001b[39mif\u001b[39;00m add_control_dependencies:\n\u001b[1;32m-> <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/framework/func_graph.py?line=1123'>1124</a>\u001b[0m   x \u001b[39m=\u001b[39m deps_ctx\u001b[39m.\u001b[39;49mmark_as_return(x)\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/framework/func_graph.py?line=1124'>1125</a>\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[1;32md:\\My projects\\chatbot\\model\\env\\lib\\site-packages\\tensorflow\\python\\framework\\auto_control_deps.py:250\u001b[0m, in \u001b[0;36mAutomaticControlDependencies.mark_as_return\u001b[1;34m(self, tensor)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/framework/auto_control_deps.py?line=244'>245</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m tensor_array_ops\u001b[39m.\u001b[39mbuild_ta_with_new_flow(tensor, flow)\n\u001b[0;32m    <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/framework/auto_control_deps.py?line=245'>246</a>\u001b[0m \u001b[39m# We want to make the return values depend on the stateful operations, but\u001b[39;00m\n\u001b[0;32m    <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/framework/auto_control_deps.py?line=246'>247</a>\u001b[0m \u001b[39m# we don't want to introduce a cycle, so we make the return value the result\u001b[39;00m\n\u001b[0;32m    <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/framework/auto_control_deps.py?line=247'>248</a>\u001b[0m \u001b[39m# of a new identity operation that the stateful operations definitely don't\u001b[39;00m\n\u001b[0;32m    <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/framework/auto_control_deps.py?line=248'>249</a>\u001b[0m \u001b[39m# depend on.\u001b[39;00m\n\u001b[1;32m--> <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/framework/auto_control_deps.py?line=249'>250</a>\u001b[0m tensor \u001b[39m=\u001b[39m array_ops\u001b[39m.\u001b[39;49midentity(tensor)\n\u001b[0;32m    <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/framework/auto_control_deps.py?line=250'>251</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_returned_tensors\u001b[39m.\u001b[39madd(tensor)\n\u001b[0;32m    <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/framework/auto_control_deps.py?line=251'>252</a>\u001b[0m \u001b[39mreturn\u001b[39;00m tensor\n",
      "File \u001b[1;32md:\\My projects\\chatbot\\model\\env\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/util/traceback_utils.py?line=147'>148</a>\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/util/traceback_utils.py?line=148'>149</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/util/traceback_utils.py?line=149'>150</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/util/traceback_utils.py?line=150'>151</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/util/traceback_utils.py?line=151'>152</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32md:\\My projects\\chatbot\\model\\env\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/util/dispatch.py?line=1079'>1080</a>\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/util/dispatch.py?line=1080'>1081</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/util/dispatch.py?line=1081'>1082</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/util/dispatch.py?line=1082'>1083</a>\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/util/dispatch.py?line=1083'>1084</a>\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/util/dispatch.py?line=1084'>1085</a>\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/util/dispatch.py?line=1085'>1086</a>\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32md:\\My projects\\chatbot\\model\\env\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:287\u001b[0m, in \u001b[0;36midentity\u001b[1;34m(input, name)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/ops/array_ops.py?line=282'>283</a>\u001b[0m \u001b[39mif\u001b[39;00m context\u001b[39m.\u001b[39mexecuting_eagerly() \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39minput\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mgraph\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/ops/array_ops.py?line=283'>284</a>\u001b[0m   \u001b[39m# Make sure we get an input with handle data attached from resource\u001b[39;00m\n\u001b[0;32m    <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/ops/array_ops.py?line=284'>285</a>\u001b[0m   \u001b[39m# variables. Variables have correct handle data when graph building.\u001b[39;00m\n\u001b[0;32m    <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/ops/array_ops.py?line=285'>286</a>\u001b[0m   \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39mconvert_to_tensor(\u001b[39minput\u001b[39m)\n\u001b[1;32m--> <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/ops/array_ops.py?line=286'>287</a>\u001b[0m ret \u001b[39m=\u001b[39m gen_array_ops\u001b[39m.\u001b[39;49midentity(\u001b[39minput\u001b[39;49m, name\u001b[39m=\u001b[39;49mname)\n\u001b[0;32m    <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/ops/array_ops.py?line=287'>288</a>\u001b[0m \u001b[39m# Propagate handle data for happier shape inference for resource variables.\u001b[39;00m\n\u001b[0;32m    <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/ops/array_ops.py?line=288'>289</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39minput\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m_handle_data\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[1;32md:\\My projects\\chatbot\\model\\env\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py:4076\u001b[0m, in \u001b[0;36midentity\u001b[1;34m(input, name)\u001b[0m\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/ops/gen_array_ops.py?line=4073'>4074</a>\u001b[0m     \u001b[39mpass\u001b[39;00m  \u001b[39m# Add nodes to the TensorFlow graph.\u001b[39;00m\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/ops/gen_array_ops.py?line=4074'>4075</a>\u001b[0m \u001b[39m# Add nodes to the TensorFlow graph.\u001b[39;00m\n\u001b[1;32m-> <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/ops/gen_array_ops.py?line=4075'>4076</a>\u001b[0m _, _, _op, _outputs \u001b[39m=\u001b[39m _op_def_library\u001b[39m.\u001b[39;49m_apply_op_helper(\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/ops/gen_array_ops.py?line=4076'>4077</a>\u001b[0m       \u001b[39m\"\u001b[39;49m\u001b[39mIdentity\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39minput\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39minput\u001b[39;49m, name\u001b[39m=\u001b[39;49mname)\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/ops/gen_array_ops.py?line=4077'>4078</a>\u001b[0m _result \u001b[39m=\u001b[39m _outputs[:]\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/ops/gen_array_ops.py?line=4078'>4079</a>\u001b[0m \u001b[39mif\u001b[39;00m _execute\u001b[39m.\u001b[39mmust_record_gradient():\n",
      "File \u001b[1;32md:\\My projects\\chatbot\\model\\env\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:740\u001b[0m, in \u001b[0;36m_apply_op_helper\u001b[1;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/framework/op_def_library.py?line=734'>735</a>\u001b[0m must_colocate_inputs \u001b[39m=\u001b[39m [val \u001b[39mfor\u001b[39;00m arg, val \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(op_def\u001b[39m.\u001b[39minput_arg, inputs)\n\u001b[0;32m    <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/framework/op_def_library.py?line=735'>736</a>\u001b[0m                         \u001b[39mif\u001b[39;00m arg\u001b[39m.\u001b[39mis_ref]\n\u001b[0;32m    <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/framework/op_def_library.py?line=736'>737</a>\u001b[0m \u001b[39mwith\u001b[39;00m _MaybeColocateWith(must_colocate_inputs):\n\u001b[0;32m    <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/framework/op_def_library.py?line=737'>738</a>\u001b[0m   \u001b[39m# Add Op to graph\u001b[39;00m\n\u001b[0;32m    <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/framework/op_def_library.py?line=738'>739</a>\u001b[0m   \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m--> <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/framework/op_def_library.py?line=739'>740</a>\u001b[0m   op \u001b[39m=\u001b[39m g\u001b[39m.\u001b[39;49m_create_op_internal(op_type_name, inputs, dtypes\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/framework/op_def_library.py?line=740'>741</a>\u001b[0m                              name\u001b[39m=\u001b[39;49mscope, input_types\u001b[39m=\u001b[39;49minput_types,\n\u001b[0;32m    <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/framework/op_def_library.py?line=741'>742</a>\u001b[0m                              attrs\u001b[39m=\u001b[39;49mattr_protos, op_def\u001b[39m=\u001b[39;49mop_def)\n\u001b[0;32m    <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/framework/op_def_library.py?line=743'>744</a>\u001b[0m \u001b[39m# `outputs` is returned as a separate return value so that the output\u001b[39;00m\n\u001b[0;32m    <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/framework/op_def_library.py?line=744'>745</a>\u001b[0m \u001b[39m# tensors can the `op` per se can be decoupled so that the\u001b[39;00m\n\u001b[0;32m    <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/framework/op_def_library.py?line=745'>746</a>\u001b[0m \u001b[39m# `op_callbacks` can function properly. See framework/op_callbacks.py\u001b[39;00m\n\u001b[0;32m    <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/framework/op_def_library.py?line=746'>747</a>\u001b[0m \u001b[39m# for more details.\u001b[39;00m\n\u001b[0;32m    <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/framework/op_def_library.py?line=747'>748</a>\u001b[0m outputs \u001b[39m=\u001b[39m op\u001b[39m.\u001b[39moutputs\n",
      "File \u001b[1;32md:\\My projects\\chatbot\\model\\env\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:693\u001b[0m, in \u001b[0;36mFuncGraph._create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/framework/func_graph.py?line=690'>691</a>\u001b[0m   inp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcapture(inp)\n\u001b[0;32m    <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/framework/func_graph.py?line=691'>692</a>\u001b[0m   captured_inputs\u001b[39m.\u001b[39mappend(inp)\n\u001b[1;32m--> <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/framework/func_graph.py?line=692'>693</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(FuncGraph, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m_create_op_internal(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/framework/func_graph.py?line=693'>694</a>\u001b[0m     op_type, captured_inputs, dtypes, input_types, name, attrs, op_def,\n\u001b[0;32m    <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/framework/func_graph.py?line=694'>695</a>\u001b[0m     compute_device)\n",
      "File \u001b[1;32md:\\My projects\\chatbot\\model\\env\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:3776\u001b[0m, in \u001b[0;36mGraph._create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/framework/ops.py?line=3772'>3773</a>\u001b[0m \u001b[39m# _create_op_helper mutates the new Operation. `_mutation_lock` ensures a\u001b[39;00m\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/framework/ops.py?line=3773'>3774</a>\u001b[0m \u001b[39m# Session.run call cannot occur between creating and mutating the op.\u001b[39;00m\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/framework/ops.py?line=3774'>3775</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mutation_lock():\n\u001b[1;32m-> <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/framework/ops.py?line=3775'>3776</a>\u001b[0m   ret \u001b[39m=\u001b[39m Operation(\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/framework/ops.py?line=3776'>3777</a>\u001b[0m       node_def,\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/framework/ops.py?line=3777'>3778</a>\u001b[0m       \u001b[39mself\u001b[39;49m,\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/framework/ops.py?line=3778'>3779</a>\u001b[0m       inputs\u001b[39m=\u001b[39;49minputs,\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/framework/ops.py?line=3779'>3780</a>\u001b[0m       output_types\u001b[39m=\u001b[39;49mdtypes,\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/framework/ops.py?line=3780'>3781</a>\u001b[0m       control_inputs\u001b[39m=\u001b[39;49mcontrol_inputs,\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/framework/ops.py?line=3781'>3782</a>\u001b[0m       input_types\u001b[39m=\u001b[39;49minput_types,\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/framework/ops.py?line=3782'>3783</a>\u001b[0m       original_op\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_default_original_op,\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/framework/ops.py?line=3783'>3784</a>\u001b[0m       op_def\u001b[39m=\u001b[39;49mop_def)\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/framework/ops.py?line=3784'>3785</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_op_helper(ret, compute_device\u001b[39m=\u001b[39mcompute_device)\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/framework/ops.py?line=3785'>3786</a>\u001b[0m \u001b[39mreturn\u001b[39;00m ret\n",
      "File \u001b[1;32md:\\My projects\\chatbot\\model\\env\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:2171\u001b[0m, in \u001b[0;36mOperation.__init__\u001b[1;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/framework/ops.py?line=2168'>2169</a>\u001b[0m   \u001b[39mif\u001b[39;00m op_def \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/framework/ops.py?line=2169'>2170</a>\u001b[0m     op_def \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_graph\u001b[39m.\u001b[39m_get_op_def(node_def\u001b[39m.\u001b[39mop)\n\u001b[1;32m-> <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/framework/ops.py?line=2170'>2171</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_c_op \u001b[39m=\u001b[39m _create_c_op(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_graph, node_def, inputs,\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/framework/ops.py?line=2171'>2172</a>\u001b[0m                             control_input_ops, op_def)\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/framework/ops.py?line=2172'>2173</a>\u001b[0m   name \u001b[39m=\u001b[39m compat\u001b[39m.\u001b[39mas_str(node_def\u001b[39m.\u001b[39mname)\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/framework/ops.py?line=2174'>2175</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_traceback \u001b[39m=\u001b[39m tf_stack\u001b[39m.\u001b[39mextract_stack_for_node(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_c_op)\n",
      "File \u001b[1;32md:\\My projects\\chatbot\\model\\env\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/util/traceback_utils.py?line=147'>148</a>\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/util/traceback_utils.py?line=148'>149</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/util/traceback_utils.py?line=149'>150</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/util/traceback_utils.py?line=150'>151</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/util/traceback_utils.py?line=151'>152</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32md:\\My projects\\chatbot\\model\\env\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:2010\u001b[0m, in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/framework/ops.py?line=2005'>2006</a>\u001b[0m   pywrap_tf_session\u001b[39m.\u001b[39mTF_SetAttrValueProto(op_desc, compat\u001b[39m.\u001b[39mas_str(name),\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/framework/ops.py?line=2006'>2007</a>\u001b[0m                                          serialized)\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/framework/ops.py?line=2008'>2009</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/framework/ops.py?line=2009'>2010</a>\u001b[0m   c_op \u001b[39m=\u001b[39m pywrap_tf_session\u001b[39m.\u001b[39;49mTF_FinishOperation(op_desc)\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/framework/ops.py?line=2010'>2011</a>\u001b[0m \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mInvalidArgumentError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/framework/ops.py?line=2011'>2012</a>\u001b[0m   \u001b[39m# Convert to ValueError for backwards compatibility.\u001b[39;00m\n\u001b[0;32m   <a href='file:///d%3A/My%20projects/chatbot/model/env/lib/site-packages/tensorflow/python/framework/ops.py?line=2012'>2013</a>\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(e\u001b[39m.\u001b[39mmessage)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "enc_model , dec_model = make_inference_models()\n",
    "\n",
    "enc_model.save( 'enc_model.h5' ) \n",
    "dec_model.save( 'dec_model.h5' ) \n",
    "model.save( 'model.h5' ) \n",
    "\n",
    "for epoch in range( encoder_input_data.shape[0] ):\n",
    "    states_values = enc_model.predict( str_to_tokens( input( 'User: ' ) ) )\n",
    "    empty_target_seq = np.zeros( ( 1 , 1 ) )\n",
    "    \n",
    "    empty_target_seq[0, 0] = output_word_dict['start']\n",
    "    stop_condition = False\n",
    "    decoded_translation = ''\n",
    "    while not stop_condition :\n",
    "        dec_outputs , h , c = dec_model.predict([ empty_target_seq ] + states_values )\n",
    "        sampled_word_index = np.argmax( dec_outputs[0, -1, :] )\n",
    "        sampled_word = None\n",
    "        print(sampled_word_index)\n",
    "        for word , index in output_word_dict.items() :\n",
    "            if sampled_word_index == index :\n",
    "                decoded_translation += ' {}'.format( word )\n",
    "                sampled_word = word\n",
    "        print(sampled_word,sampled_word_index)\n",
    "        if sampled_word == 'end' or len(decoded_translation.split()) > max_output_length:\n",
    "            stop_condition = True\n",
    "            \n",
    "        empty_target_seq = np.zeros( ( 1 , 1 ) )  \n",
    "        empty_target_seq[ 0 , 0 ] = sampled_word_index\n",
    "        states_values = [ h , c ] \n",
    "\n",
    "    print( \"Bot:\" +decoded_translation.replace(' end', '') )\n",
    "    print()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_cxalVo74-qm"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Copy of Training.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
